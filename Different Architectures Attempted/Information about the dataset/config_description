================================================
FILE: configs/actual_lie/bert+context+power.jsonnet
================================================
{
    "pytorch_seed": 1994,
    "numpy_seed": 1994,
    "random_seed": 1994,
    "dataset_reader": {
        "type": "diplomacy_reader",
        "label_key": "sender_labels",
        "lazy": false,
        "token_indexers": {
            "bert": {
                "type": "bert-pretrained",
                "do_lowercase": true,
                "max_pieces": 20,
                "pretrained_model": "bert-base-uncased",
                "use_starting_offsets": true
            }
        },
        "tokenizer": {
            "type": "pretrained_transformer",
            "do_lowercase": true,
            "model_name": "bert-base-uncased"
        },
        "use_game_scores": true
    },
    "iterator": {
        "type": "basic",
        "batch_size": 4
    },
    "model": {
        "type": "hierarchical_lstm",
        "conversation_encoder": {
            "type": "lstm",
            "bidirectional": false,
            "hidden_size": 200,
            "input_size": 768
        },
        "dropout": "0.5",
        "embedder": {
            "allow_unmatched_keys": true,
            "embedder_to_indexer_map": {
                "bert": [
                    "bert",
                    "bert-offsets"
                ]
            },
            "token_embedders": {
                "bert": {
                    "type": "bert-pretrained",
                    "pretrained_model": "bert-base-uncased"
                }
            }
        },
        "message_encoder": {
            "type": "bert_pooler",
            "pretrained_model": "bert-base-uncased",
            "requires_grad": true
        },
        "pos_weight": "15",
        "use_game_scores": true
    },
    "train_data_path": "data/train.jsonl",
    "validation_data_path": "data/validation.jsonl",
    "test_data_path": "data/test.jsonl",
    "trainer": {
        "cuda_device": 0,
        "grad_clipping": 1,
        "num_epochs": 15,
        "optimizer": {
            "type": "adam",
            "lr": "0.0003"
        },
        "patience": 10,
        "validation_metric": "+macro_fscore"
    },
    "evaluate_on_test": true
}



================================================
FILE: configs/actual_lie/bert+context.jsonnet
================================================
{
    "pytorch_seed": 1994,
    "numpy_seed": 1994,
    "random_seed": 1994,
    "dataset_reader": {
        "type": "diplomacy_reader",
        "label_key": "sender_labels",
        "lazy": false,
        "token_indexers": {
            "bert": {
                "type": "bert-pretrained",
                "do_lowercase": true,
                "max_pieces": 20,
                "pretrained_model": "bert-base-uncased",
                "use_starting_offsets": true
            }
        },
        "tokenizer": {
            "type": "pretrained_transformer",
            "do_lowercase": true,
            "model_name": "bert-base-uncased"
        },
        "use_game_scores": false
    },
    "iterator": {
        "type": "basic",
        "batch_size": 4
    },
    "model": {
        "type": "hierarchical_lstm",
        "conversation_encoder": {
            "type": "lstm",
            "bidirectional": false,
            "hidden_size": 200,
            "input_size": 768
        },
        "dropout": "0.4",
        "embedder": {
            "allow_unmatched_keys": true,
            "embedder_to_indexer_map": {
                "bert": [
                    "bert",
                    "bert-offsets"
                ]
            },
            "token_embedders": {
                "bert": {
                    "type": "bert-pretrained",
                    "pretrained_model": "bert-base-uncased"
                }
            }
        },
        "message_encoder": {
            "type": "bert_pooler",
            "pretrained_model": "bert-base-uncased",
            "requires_grad": true
        },
        "pos_weight": "15",
        "use_game_scores": false
    },
    "train_data_path": "data/train.jsonl",
    "validation_data_path": "data/validation.jsonl",
    "test_data_path": "data/test.jsonl",
    "trainer": {
        "cuda_device": 0,
        "grad_clipping": 1,
        "num_epochs": 15,
        "optimizer": {
            "type": "adam",
            "lr": "0.0003"
        },
        "patience": 10,
        "validation_metric": "+macro_fscore"
    },
    "evaluate_on_test": true
}



================================================
FILE: configs/actual_lie/contextlstm+power.jsonnet
================================================
{
    "pytorch_seed": 1994,
    "numpy_seed": 1994,
    "random_seed": 1994,
    "dataset_reader": {
        "type": "diplomacy_reader",
        "label_key": "sender_labels",
        "lazy": false,
        "token_indexers": {
            "tokens": {
                "type": "single_id",
                "lowercase_tokens": true
            }
        },
        "use_game_scores": true
    },
    "iterator": {
        "type": "basic",
        "batch_size": 4
    },
    "model": {
        "type": "hierarchical_lstm",
        "conversation_encoder": {
            "type": "lstm",
            "bidirectional": false,
            "hidden_size": 200,
            "input_size": 200
        },
        "dropout": "0.3",
        "embedder": {
            "tokens": {
                "type": "embedding",
                "embedding_dim": 200,
                "pretrained_file": "(http://nlp.stanford.edu/data/glove.twitter.27B.zip)#glove.twitter.27B.200d.txt",
                "trainable": false
            }
        },
        "message_encoder": {
            "type": "pooled_rnn",
            "encoder": {
                "type": "lstm",
                "bidirectional": true,
                "hidden_size": 100,
                "input_size": 200
            },
            "poolers": "max"
        },
        "pos_weight": "10",
        "use_game_scores": true
    },
    "train_data_path": "data/train.jsonl",
    "validation_data_path": "data/validation.jsonl",
    "test_data_path": "data/test.jsonl",
    "trainer": {
        "cuda_device": 0,
        "grad_clipping": 1,
        "num_epochs": 15,
        "optimizer": {
            "type": "adam",
            "lr": "0.003"
        },
        "patience": 10,
        "validation_metric": "+macro_fscore"
    },
    "evaluate_on_test": true
}



================================================
FILE: configs/actual_lie/contextlstm.jsonnet
================================================
{
    "pytorch_seed": 1994,
    "numpy_seed": 1994,
    "random_seed": 1994,
    "dataset_reader": {
        "type": "diplomacy_reader",
        "label_key": "sender_labels",
        "lazy": false,
        "token_indexers": {
            "tokens": {
                "type": "single_id",
                "lowercase_tokens": true
            }
        },
        "use_game_scores": false
    },
    "iterator": {
        "type": "basic",
        "batch_size": 4
    },
    "model": {
        "type": "hierarchical_lstm",
        "conversation_encoder": {
            "type": "lstm",
            "bidirectional": false,
            "hidden_size": 200,
            "input_size": 200
        },
        "dropout": "0.3",
        "embedder": {
            "tokens": {
                "type": "embedding",
                "embedding_dim": 200,
                "pretrained_file": "(http://nlp.stanford.edu/data/glove.twitter.27B.zip)#glove.twitter.27B.200d.txt",
                "trainable": false
            }
        },
        "message_encoder": {
            "type": "pooled_rnn",
            "encoder": {
                "type": "lstm",
                "bidirectional": true,
                "hidden_size": 100,
                "input_size": 200
            },
            "poolers": "max"
        },
        "pos_weight": "10",
        "use_game_scores": false
    },
    "train_data_path": "data/train.jsonl",
    "validation_data_path": "data/validation.jsonl",
    "test_data_path": "data/test.jsonl",
    "trainer": {
        "cuda_device": 0,
        "grad_clipping": 1,
        "num_epochs": 15,
        "optimizer": {
            "type": "adam",
            "lr": "0.003"
        },
        "patience": 10,
        "validation_metric": "+macro_fscore"
    },
    "evaluate_on_test": true
}



================================================
FILE: configs/actual_lie/lstm.jsonnet
================================================
{
    "pytorch_seed": 1994,
    "numpy_seed": 1994,
    "random_seed": 1994,
    "dataset_reader": {
        "lazy": false,
        "sender_annotation": true,
        "token_indexers": {
            "tokens": {
                "lowercase_tokens": true,
                "namespace": "tokens",
                "type": "single_id"
            }
        },
        "type": "message_reader"
    },
    "evaluate_on_test": true,
    "iterator": {
        "batch_size": 32,
        "sorting_keys": [
            [
                "message",
                "num_tokens"
            ]
        ],
        "type": "bucket"
    },
    "model": {
        "dropout": 0.5,
        "embedder": {
            "tokens": {
                "embedding_dim": 200,
                "pretrained_file": "(http://nlp.stanford.edu/data/glove.twitter.27B.zip)#glove.twitter.27B.200d.txt",
                "trainable": false,
                "type": "embedding"
            }
        },
        "encoder": {
            "encoder": {
            "bidirectional": true,
            "hidden_size": 100,
            "input_size": 200,
            "type": "lstm"
            },
            "type": 'pooled_rnn',
            "poolers": "max",
        },
        posclass_weight: 30.0,
        use_power: false,
        "type": "lie_detector"
    },
    "test_data_path": 'data/test_sm.jsonl',
    "train_data_path": 'data/train_sm.jsonl',
    "validation_data_path": 'data/validation_sm.jsonl',
    "trainer": {
        "cuda_device": 0,
        "grad_clipping": 1.0,
        "num_epochs": 15,
        "patience": 5,
        "optimizer": {
            "lr": 0.003,
            "type": "adam"
        },
        "validation_metric": "+macro_fscore"
    }
}


================================================
FILE: configs/suspected_lie/bert+context+power.jsonnet
================================================
{
    "pytorch_seed": 1994,
    "numpy_seed": 1994,
    "random_seed": 1994,
    "dataset_reader": {
        "type": "diplomacy_reader",
        "label_key": "receiver_labels",
        "lazy": false,
        "token_indexers": {
            "bert": {
                "type": "bert-pretrained",
                "do_lowercase": true,
                "max_pieces": 20,
                "pretrained_model": "bert-base-uncased",
                "use_starting_offsets": true
            }
        },
        "tokenizer": {
            "type": "pretrained_transformer",
            "do_lowercase": true,
            "model_name": "bert-base-uncased"
        },
        "use_game_scores": true
    },
    "iterator": {
        "type": "basic",
        "batch_size": 4
    },
    "model": {
        "type": "hierarchical_lstm",
        "conversation_encoder": {
            "type": "lstm",
            "bidirectional": false,
            "hidden_size": 200,
            "input_size": 768
        },
        "dropout": "0.1",
        "embedder": {
            "allow_unmatched_keys": true,
            "embedder_to_indexer_map": {
                "bert": [
                    "bert",
                    "bert-offsets"
                ]
            },
            "token_embedders": {
                "bert": {
                    "type": "bert-pretrained",
                    "pretrained_model": "bert-base-uncased"
                }
            }
        },
        "message_encoder": {
            "type": "bert_pooler",
            "pretrained_model": "bert-base-uncased",
            "requires_grad": true
        },
        "pos_weight": "10",
        "use_game_scores": true
    },
    "test_data_path": "data/test.jsonl",
    "train_data_path": "data/train.jsonl",
    "validation_data_path": "data/validation.jsonl",
    "trainer": {
        "cuda_device": 0,
        "grad_clipping": 1,
        "num_epochs": 15,
        "optimizer": {
            "type": "adam",
            "lr": "0.0003"
        },
        "patience": 10,
        "validation_metric": "+macro_fscore"
    },
    "evaluate_on_test": true
}



================================================
FILE: configs/suspected_lie/bert+context.jsonnet
================================================
{
    "pytorch_seed": 1994,
    "numpy_seed": 1994,
    "random_seed": 1994,
    "dataset_reader": {
        "type": "diplomacy_reader",
        "label_key": "receiver_labels",
        "lazy": false,
        "token_indexers": {
            "bert": {
                "type": "bert-pretrained",
                "do_lowercase": true,
                "max_pieces": 20,
                "pretrained_model": "bert-base-uncased",
                "use_starting_offsets": true
            }
        },
        "tokenizer": {
            "type": "pretrained_transformer",
            "do_lowercase": true,
            "model_name": "bert-base-uncased"
        },
        "use_game_scores": false
    },
    "iterator": {
        "type": "basic",
        "batch_size": 4
    },
    "model": {
        "type": "hierarchical_lstm",
        "conversation_encoder": {
            "type": "lstm",
            "bidirectional": false,
            "hidden_size": 200,
            "input_size": 768
        },
        "dropout": "0.1",
        "embedder": {
            "allow_unmatched_keys": true,
            "embedder_to_indexer_map": {
                "bert": [
                    "bert",
                    "bert-offsets"
                ]
            },
            "token_embedders": {
                "bert": {
                    "type": "bert-pretrained",
                    "pretrained_model": "bert-base-uncased"
                }
            }
        },
        "message_encoder": {
            "type": "bert_pooler",
            "pretrained_model": "bert-base-uncased",
            "requires_grad": true
        },
        "pos_weight": "20",
        "use_game_scores": false
    },
    "test_data_path": "data/test.jsonl",
    "train_data_path": "data/train.jsonl",
    "validation_data_path": "data/validation.jsonl",
    "trainer": {
        "cuda_device": 0,
        "grad_clipping": 1,
        "num_epochs": 15,
        "optimizer": {
            "type": "adam",
            "lr": "0.0003"
        },
        "patience": 10,
        "validation_metric": "+macro_fscore"
    },
    "evaluate_on_test": true
}



================================================
FILE: configs/suspected_lie/contextlstm+power.jsonnet
================================================
{
    "pytorch_seed": 1994,
    "numpy_seed": 1994,
    "random_seed": 1994,
    "dataset_reader": {
        "type": "diplomacy_reader",
        "label_key": "receiver_labels",
        "lazy": false,
        "token_indexers": {
            "tokens": {
                "type": "single_id",
                "lowercase_tokens": true
            }
        },
        "use_game_scores": true
    },
    "iterator": {
        "type": "basic",
        "batch_size": 4
    },
    "model": {
        "type": "hierarchical_lstm",
        "conversation_encoder": {
            "type": "lstm",
            "bidirectional": false,
            "hidden_size": 200,
            "input_size": 200
        },
        "dropout": "0.4",
        "embedder": {
            "tokens": {
                "type": "embedding",
                "embedding_dim": 200,
                "pretrained_file": "(http://nlp.stanford.edu/data/glove.twitter.27B.zip)#glove.twitter.27B.200d.txt",
                "trainable": false
            }
        },
        "message_encoder": {
            "type": "pooled_rnn",
            "encoder": {
                "type": "lstm",
                "bidirectional": true,
                "hidden_size": 100,
                "input_size": 200
            },
            "poolers": "max"
        },
        "pos_weight": "10",
        "use_game_scores": true
    },
    "test_data_path": "data/test.jsonl",
    "train_data_path": "data/train.jsonl",
    "validation_data_path": "data/validation.jsonl",
    "trainer": {
        "cuda_device": 0,
        "grad_clipping": 1,
        "num_epochs": 15,
        "optimizer": {
            "type": "adam",
            "lr": "0.003"
        },
        "patience": 10,
        "validation_metric": "+macro_fscore"
    },
    "evaluate_on_test": true
}



================================================
FILE: configs/suspected_lie/contextlstm.jsonnet
================================================
{
    "pytorch_seed": 1994,
    "numpy_seed": 1994,
    "random_seed": 1994,
    "dataset_reader": {
        "type": "diplomacy_reader",
        "label_key": "receiver_labels",
        "lazy": false,
        "token_indexers": {
            "tokens": {
                "type": "single_id",
                "lowercase_tokens": true
            }
        },
        "use_game_scores": false
    },
    "iterator": {
        "type": "basic",
        "batch_size": 4
    },
    "model": {
        "type": "hierarchical_lstm",
        "conversation_encoder": {
            "type": "lstm",
            "bidirectional": false,
            "hidden_size": 200,
            "input_size": 200
        },
        "dropout": "0.4",
        "embedder": {
            "tokens": {
                "type": "embedding",
                "embedding_dim": 200,
                "pretrained_file": "(http://nlp.stanford.edu/data/glove.twitter.27B.zip)#glove.twitter.27B.200d.txt",
                "trainable": false
            }
        },
        "message_encoder": {
            "type": "pooled_rnn",
            "encoder": {
                "type": "lstm",
                "bidirectional": true,
                "hidden_size": 100,
                "input_size": 200
            },
            "poolers": "max"
        },
        "pos_weight": "15",
        "use_game_scores": false
    },
    "test_data_path": "data/test.jsonl",
    "train_data_path": "data/train.jsonl",
    "validation_data_path": "data/validation.jsonl",
    "trainer": {
        "cuda_device": 0,
        "grad_clipping": 1,
        "num_epochs": 15,
        "optimizer": {
            "type": "adam",
            "lr": "0.003"
        },
        "patience": 10,
        "validation_metric": "+macro_fscore"
    },
    "evaluate_on_test": true
}



================================================
FILE: configs/suspected_lie/lstm.jsonnet
================================================
{
    "pytorch_seed": 1994,
    "numpy_seed": 1994,
    "random_seed": 1994,
    "dataset_reader": {
        "lazy": false,
        "sender_annotation": false,
        "token_indexers": {
            "tokens": {
                "lowercase_tokens": true,
                "namespace": "tokens",
                "type": "single_id"
            }
        },
        "type": "message_reader"
    },
    "evaluate_on_test": true,
    "iterator": {
        "batch_size": 32,
        "sorting_keys": [
            [
                "message",
                "num_tokens"
            ]
        ],
        "type": "bucket"
    },
    "model": {
        "dropout": 0.5,
        "embedder": {
            "tokens": {
                "embedding_dim": 200,
                "pretrained_file": "(http://nlp.stanford.edu/data/glove.twitter.27B.zip)#glove.twitter.27B.200d.txt",
                "trainable": false,
                "type": "embedding"
            }
        },
        "encoder": {
            "encoder": {
            "bidirectional": true,
            "hidden_size": 100,
            "input_size": 200,
            "type": "lstm"
            },
            "type": 'pooled_rnn',
            "poolers": "max",
        },
        posclass_weight: 30.0,
        use_power: false,
        "type": "lie_detector"
    },
    "test_data_path": 'data/test_sm.jsonl',
    "train_data_path": 'data/train_sm.jsonl',
    "validation_data_path": 'data/validation_sm.jsonl',
    "trainer": {
        "cuda_device": 0,
        "grad_clipping": 1.0,
        "num_epochs": 15,
        "patience": 5,
        "optimizer": {
            "lr": 0.003,
            "type": "adam"
        },
        "validation_metric": "+macro_fscore"
    }
}

