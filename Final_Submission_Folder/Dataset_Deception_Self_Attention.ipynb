{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11393166,"sourceType":"datasetVersion","datasetId":7105609}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install required libraries\n!pip install sentence-transformers spacy nltk\n!python -m spacy download en_core_web_sm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T14:27:56.063084Z","iopub.execute_input":"2025-04-14T14:27:56.063833Z","iopub.status.idle":"2025-04-14T14:28:07.646828Z","shell.execute_reply.started":"2025-04-14T14:27:56.063804Z","shell.execute_reply":"2025-04-14T14:28:07.646017Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\nRequirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.7.5)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.5.1+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.2)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.2)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.26.4)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.13.1)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (14.0.0)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->spacy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->spacy) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.0->spacy) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.19.0->spacy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.19.0->spacy) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\nCollecting en-core-web-sm==3.7.1\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.11/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.12)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.11)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.1)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.15.1)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.11.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.6)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.33.1)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.13.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2025.1.31)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.8)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (14.0.0)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.19.1)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.17.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\nIf you are in a Jupyter or Colab notebook, you may need to restart Python in\norder to load all the package's dependencies. You can do this by selecting the\n'Restart kernel' or 'Restart runtime' option.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom sentence_transformers import SentenceTransformer\nfrom torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\nimport json\nfrom tqdm import tqdm\nimport logging\nimport time\nfrom sklearn.metrics import precision_recall_fscore_support, confusion_matrix, roc_auc_score, roc_curve\nimport spacy\nimport nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nimport numpy as np\nimport itertools\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom collections import Counter","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T04:35:51.204295Z","iopub.execute_input":"2025-04-15T04:35:51.204606Z","iopub.status.idle":"2025-04-15T04:36:16.387424Z","shell.execute_reply.started":"2025-04-15T04:35:51.204584Z","shell.execute_reply":"2025-04-15T04:36:16.386673Z"}},"outputs":[{"name":"stderr","text":"2025-04-15 04:35:57.790981: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1744691757.970822      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1744691758.025310      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":" #Download VADER lexicon\nimport torch.nn.functional as F\nnltk.download('vader_lexicon')\n\n# Setup logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(__name__)\n\n# Device configuration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nlogger.info(f\"Using device: {device}\")\n\n# Load spaCy and VADER\nlogger.info(\"Loading spaCy and VADER...\")\nstart_time = time.time()\nnlp = spacy.load('en_core_web_sm', disable=['ner', 'lemmatizer'])\nsid = SentimentIntensityAnalyzer()\nlogger.info(f\"spaCy and VADER loaded in {time.time() - start_time:.2f} seconds\")\n\n# Load Sentence-BERT model\nlogger.info(\"Loading Sentence-BERT model...\")\nstart_time = time.time()\nsentence_bert = SentenceTransformer('paraphrase-MiniLM-L6-v2').to(device)\nsentence_bert.eval()\nlogger.info(f\"Sentence-BERT loaded in {time.time() - start_time:.2f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T04:36:37.054682Z","iopub.execute_input":"2025-04-15T04:36:37.054858Z","iopub.status.idle":"2025-04-15T04:36:39.938248Z","shell.execute_reply.started":"2025-04-15T04:36:37.054843Z","shell.execute_reply":"2025-04-15T04:36:39.937734Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Set seed for reproducibility\nimport random\n\nseed = 100\n\ntorch.manual_seed(seed)\nrandom.seed(seed)\ntorch.cuda.manual_seed_all(seed)\nrandom.seed(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark=False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T07:49:33.502736Z","iopub.execute_input":"2025-04-15T07:49:33.502977Z","iopub.status.idle":"2025-04-15T07:49:33.508301Z","shell.execute_reply.started":"2025-04-15T07:49:33.502961Z","shell.execute_reply":"2025-04-15T07:49:33.507713Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"\n# Model Definition\nclass EnhancedDeceptionDetector(nn.Module):\n    def __init__(self, num_countries, num_seasons, num_years, \n                 sentence_emb_dim=384, ling_feature_dim=6, country_emb_dim=16, \n                 season_emb_dim=8, year_emb_dim=8, hidden_dim=64, dropout=0.4):\n        super(EnhancedDeceptionDetector, self).__init__()\n        self.ling_feature_dim = ling_feature_dim\n        self.country_embedding = nn.Embedding(num_countries + 1, country_emb_dim, padding_idx=num_countries)\n        self.season_embedding = nn.Embedding(num_seasons + 1, season_emb_dim, padding_idx=num_seasons)\n        self.year_embedding = nn.Embedding(num_years + 1, year_emb_dim, padding_idx=num_years)\n        \n        input_dim = sentence_emb_dim + ling_feature_dim + (country_emb_dim * 2) + season_emb_dim + year_emb_dim + 2\n        self.ling_projection = nn.Linear(ling_feature_dim, ling_feature_dim) if ling_feature_dim > 0 else None\n        self.input_projection = nn.Linear(input_dim, hidden_dim)\n        \n        self.lstm = nn.LSTM(hidden_dim, hidden_dim, num_layers=1, bidirectional=True, batch_first=True)\n        self.layer_norm = nn.LayerNorm(hidden_dim * 2)\n        self.classifier = nn.Linear(hidden_dim * 2, 1)\n        self.dropout = nn.Dropout(dropout)\n        self.attention = nn.Linear(hidden_dim * 2, 1)\n\n    def forward(self, messages_list, ling_features, senders, receivers, seasons, years, \n                game_scores, game_score_deltas, lengths):\n        batch_size = len(messages_list)\n        \n        message_embs_list = []\n        for batch_idx in range(batch_size):\n            msgs = ['' if msg == '[EMPTY]' else msg for msg in messages_list[batch_idx]]\n            with torch.no_grad():\n                embs = sentence_bert.encode(\n                    msgs, convert_to_tensor=True, device=device, show_progress_bar=False, batch_size=32\n                )\n            message_embs_list.append(embs)\n        \n        message_embs_padded = pad_sequence(message_embs_list, batch_first=True, padding_value=0)\n        \n        if self.ling_feature_dim > 0:\n            ling_features_padded = pad_sequence(ling_features, batch_first=True, padding_value=0).to(device)\n            ling_features_padded = self.ling_projection(ling_features_padded)\n        else:\n            ling_features_padded = torch.zeros(batch_size, message_embs_padded.size(1), 0, device=device)\n        \n        senders_emb = self.country_embedding(senders)\n        receivers_emb = self.country_embedding(receivers)\n        seasons_emb = self.season_embedding(seasons)\n        years_emb = self.year_embedding(years)\n        game_scores = game_scores.unsqueeze(-1)\n        game_score_deltas = game_score_deltas.unsqueeze(-1)\n\n        combined = torch.cat([\n            message_embs_padded, ling_features_padded, senders_emb, receivers_emb,\n            seasons_emb, years_emb, game_scores, game_score_deltas\n        ], dim=2)\n        \n        combined = self.input_projection(combined)\n        combined = self.dropout(combined)\n        \n        packed_input = pack_padded_sequence(combined, lengths, batch_first=True, enforce_sorted=False)\n        lstm_out_packed, _ = self.lstm(packed_input)\n        lstm_out, _ = pad_packed_sequence(lstm_out_packed, batch_first=True)\n        \n        lstm_out = self.layer_norm(lstm_out)\n        attn_weights = torch.softmax(self.attention(lstm_out), dim=1)\n        context = torch.sum(attn_weights * lstm_out, dim=1)\n        context = self.layer_norm(context)\n        final_pred = self.classifier(context).unsqueeze(1)\n        return final_pred.expand(-1, lstm_out.size(1), -1)\n\n# Data Preprocessing\ndef preprocess_data(data_file, country_map=None, season_map=None, year_map=None, use_ling_features=True, ling_stats=None):\n    logger.info(f\"Preprocessing {data_file}\")\n    with open(data_file, 'r') as f:\n        data = [json.loads(line) for line in f]\n    \n    if country_map is None:\n        countries = set()\n        for game in data:\n            countries.update(game['speakers'])\n            countries.update(game['receivers'])\n        country_map = {c: i for i, c in enumerate(sorted(countries))}\n        logger.info(f\"Created country map with {len(country_map)} countries\")\n    \n    if season_map is None:\n        seasons = set()\n        for game in data:\n            seasons.update(game['seasons'])\n        season_map = {s: i for i, s in enumerate(sorted(seasons))}\n        logger.info(f\"Created season map with {len(season_map)} seasons\")\n    \n    if year_map is None:\n        years = set()\n        for game in data:\n            years.update(game['years'])\n        year_map = {y: i for i, y in enumerate(sorted(years))}\n        logger.info(f\"Created year map with {len(year_map)} years\")\n    \n    conversations = []\n    ling_features_all = [] if use_ling_features else None\n    for game in tqdm(data, desc=\"Processing conversations\"):\n        messages = [msg if msg else '[EMPTY]' for msg in game['messages']]\n        if len(messages) == 0:\n            continue\n        senders = [country_map[s] for s in game['speakers']]\n        receivers = [country_map[r] for r in game['receivers']]\n        seasons = [season_map[s] for s in game['seasons']]\n        years = [year_map[y] for y in game['years']]\n        game_scores = [float(gs) for gs in game['game_score']]\n        game_score_deltas = [float(gsd) for gsd in game['game_score_delta']]\n        sender_labels = [1 if l else 0 for l in game['sender_labels']]\n        receiver_labels = [-1 if l == \"NOANNOTATION\" else (1 if l else 0) for l in game['receiver_labels']]\n        \n        ling_features = []\n        for msg in messages:\n            if msg == '[EMPTY]' or not use_ling_features:\n                ling_features.append([0.0] * 6)\n            else:\n                doc = nlp(msg)\n                words = [token.text.lower() for token in doc if not token.is_punct]\n                word_count = min(len(words), 100)\n                lexical_diversity = len(set(words)) / (len(words) + 1e-8) if len(words) > 0 else 0\n                lexical_diversity = min(lexical_diversity, 1.0)\n                self_refs = min(sum(1 for token in doc if token.text.lower() in ['i', 'me', 'my', 'mine', 'myself']), 10)\n                group_refs = min(sum(1 for token in doc if token.text.lower() in ['we', 'us', 'our', 'ours', 'ourselves']), 10)\n                neg_emotion = sid.polarity_scores(msg)['neg']\n                modifiers = min(sum(1 for token in doc if token.pos_ in ['ADJ', 'ADV']), 10)\n                ling_features.append([\n                    np.log1p(word_count), lexical_diversity, self_refs, group_refs, neg_emotion, modifiers\n                ])\n            if data_file.endswith('train.jsonl'):\n                ling_features_all.append(ling_features[-1])\n        \n        conversations.append({\n            'messages': messages, 'ling_features': torch.tensor(ling_features, dtype=torch.float32),\n            'speakers': torch.tensor(senders, dtype=torch.long), 'receivers': torch.tensor(receivers, dtype=torch.long),\n            'seasons': torch.tensor(seasons, dtype=torch.long), 'years': torch.tensor(years, dtype=torch.long),\n            'game_scores': torch.tensor(game_scores, dtype=torch.float32),\n            'game_score_deltas': torch.tensor(game_score_deltas, dtype=torch.float32),\n            'sender_labels': torch.tensor(sender_labels, dtype=torch.float32),\n            'receiver_labels': torch.tensor(receiver_labels, dtype=torch.float32)\n        })\n    \n    if use_ling_features and data_file.endswith('train.jsonl'):\n        ling_features_all = np.array(ling_features_all)\n        ling_stats = {'mean': np.mean(ling_features_all, axis=0), 'std': np.std(ling_features_all, axis=0) + 1e-8}\n    elif use_ling_features and ling_stats is None:\n        raise ValueError(\"ling_stats must be provided for val/test when use_ling_features=True\")\n    \n    if use_ling_features:\n        for conv in conversations:\n            ling_features = conv['ling_features'].numpy()\n            ling_features = (ling_features - ling_stats['mean']) / ling_stats['std']\n            conv['ling_features'] = torch.tensor(ling_features, dtype=torch.float32)\n    \n    logger.info(f\"Processed {len(conversations)} conversations from {data_file}\")\n    return conversations, country_map, season_map, year_map, ling_stats\n\n# Oversample Lie Conversations\ndef oversample_lies(data, oversample_factor=2):\n    lie_convs = [conv for conv in data if any(l == 1 for l in conv['sender_labels'])]\n    oversampled = data + lie_convs * (oversample_factor - 1)\n    logger.info(f\"Oversampled: {len(data)} -> {len(oversampled)} conversations\")\n    return oversampled\n\n# Compute Metrics\ndef compute_metrics(preds, labels, mask=None):\n    if mask is not None:\n        preds = preds[mask.bool()]\n        labels = labels[mask.bool()]\n    preds = (preds > 0).float()\n    labels = labels.float()\n    \n    precision, recall, fscore, _ = precision_recall_fscore_support(labels.cpu(), preds.cpu(), average=None, labels=[0, 1], zero_division=0)\n    micro = precision_recall_fscore_support(labels.cpu(), preds.cpu(), average='micro', zero_division=0)[:3]\n    macro = precision_recall_fscore_support(labels.cpu(), preds.cpu(), average='macro', zero_division=0)[:3]\n    conf_matrix = confusion_matrix(labels.cpu(), preds.cpu(), labels=[0, 1])\n    \n    return {\n        'True_precision': precision[1], 'False_precision': precision[0],\n        'True_recall': recall[1], 'False_recall': recall[0],\n        'True_fscore': fscore[1], 'False_fscore': fscore[0],\n        'micro_precision': micro[0], 'micro_recall': micro[1], 'micro_fscore': micro[2],\n        'macro_precision': macro[0], 'macro_recall': macro[1], 'macro_fscore': macro[2],\n        'confusion_matrix': conf_matrix\n    }\n\n# Training and Evaluation\ndef train_and_evaluate(model, train_data, val_data, test_data, epochs=15, batch_size=4, lr=0.0001, patience=3,\n                      checkpoint_dir='checkpoints', start_epoch=0, checkpoint=None):\n    model = model.to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.01)\n    os.makedirs(checkpoint_dir, exist_ok=True)\n    warmup_steps = int(0.1 * epochs * (len(train_data) / batch_size))\n    def lr_lambda(step):\n        if step < warmup_steps:\n            return float(step) / warmup_steps\n        return 1.0\n    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n\n    if checkpoint is not None:\n        model.load_state_dict(checkpoint['model_state_dict'])\n        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n        start_epoch = checkpoint['epoch']\n        criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([checkpoint['pos_weight']], device=device), reduction='none')\n        print(f\"Resuming training from epoch {start_epoch}\")\n    else:\n        all_labels = [l.item() for conv in train_data for l in conv['sender_labels'] if l != -1]\n        num_lies = sum(l == 1 for l in all_labels)\n        num_truths = len(all_labels) - num_lies\n        pos_weight_val = (num_truths / num_lies) * 1.5 if num_lies > 0 else 1.0\n        criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight_val], device=device), reduction='none')\n        model.classifier.bias.data.fill_(1.0)\n\n    # Track best metrics for best_checkpoint.pt\n    best_macro_f1 = -float('inf')\n    best_false_f1 = -float('inf')\n    best_val_loss = float('inf') if checkpoint is None else checkpoint['val_loss']\n    best_metrics = None if checkpoint is None else checkpoint['metrics']\n    best_model_state = None if checkpoint is None else model.state_dict().copy()\n    epochs_no_improve = 0\n    best_pos_weight = pos_weight_val if checkpoint is None else checkpoint['pos_weight']\n\n    def evaluate_batch(data, batch_size=4):\n        model.eval()\n        total_loss = 0\n        all_preds, all_labels = [], []\n        with torch.no_grad():\n            for i in range(0, len(data), batch_size):\n                batch = data[i:i+batch_size]\n                messages = [c['messages'] for c in batch]\n                ling_features = [c['ling_features'] for c in batch]\n                senders = torch.nn.utils.rnn.pad_sequence([c['speakers'] for c in batch], batch_first=True, padding_value=model.country_embedding.padding_idx).to(device)\n                receivers = torch.nn.utils.rnn.pad_sequence([c['receivers'] for c in batch], batch_first=True, padding_value=model.country_embedding.padding_idx).to(device)\n                seasons = torch.nn.utils.rnn.pad_sequence([c['seasons'] for c in batch], batch_first=True, padding_value=model.season_embedding.padding_idx).to(device)\n                years = torch.nn.utils.rnn.pad_sequence([c['years'] for c in batch], batch_first=True, padding_value=model.year_embedding.padding_idx).to(device)\n                game_scores = torch.nn.utils.rnn.pad_sequence([c['game_scores'] for c in batch], batch_first=True, padding_value=0).to(device)\n                game_score_deltas = torch.nn.utils.rnn.pad_sequence([c['game_score_deltas'] for c in batch], batch_first=True, padding_value=0).to(device)\n                sender_labels = torch.nn.utils.rnn.pad_sequence([c['sender_labels'] for c in batch], batch_first=True, padding_value=-1).to(device)\n                lengths = [len(c['messages']) for c in batch]\n\n                final_pred = model(messages, ling_features, senders, receivers, seasons, years,\n                                  game_scores, game_score_deltas, lengths)\n                loss = criterion(final_pred.squeeze(-1), sender_labels)\n                mask = (sender_labels != -1)\n                loss = (loss * mask).sum() / (mask.sum() + 1e-8)\n                total_loss += loss.item()\n\n                all_preds.append(final_pred.squeeze(-1)[mask])\n                all_labels.append(sender_labels[mask])\n\n        avg_loss = total_loss / (len(data) / batch_size)\n        all_preds = torch.cat(all_preds)\n        all_labels = torch.cat(all_labels)\n        metrics = compute_metrics(all_preds, all_labels)\n        return avg_loss, metrics\n\n    for epoch in range(start_epoch, epochs):\n        model.train()\n        total_loss = 0\n        for i in range(0, len(train_data), batch_size):\n            optimizer.zero_grad()\n            batch = train_data[i:i+batch_size]\n            messages = [c['messages'] for c in batch]\n            ling_features = [c['ling_features'] for c in batch]\n            senders = torch.nn.utils.rnn.pad_sequence([c['speakers'] for c in batch], batch_first=True, padding_value=model.country_embedding.padding_idx).to(device)\n            receivers = torch.nn.utils.rnn.pad_sequence([c['receivers'] for c in batch], batch_first=True, padding_value=model.country_embedding.padding_idx).to(device)\n            seasons = torch.nn.utils.rnn.pad_sequence([c['seasons'] for c in batch], batch_first=True, padding_value=model.season_embedding.padding_idx).to(device)\n            years = torch.nn.utils.rnn.pad_sequence([c['years'] for c in batch], batch_first=True, padding_value=model.year_embedding.padding_idx).to(device)\n            game_scores = torch.nn.utils.rnn.pad_sequence([c['game_scores'] for c in batch], batch_first=True, padding_value=0).to(device)\n            game_score_deltas = torch.nn.utils.rnn.pad_sequence([c['game_score_deltas'] for c in batch], batch_first=True, padding_value=0).to(device)\n            sender_labels = torch.nn.utils.rnn.pad_sequence([c['sender_labels'] for c in batch], batch_first=True, padding_value=-1).to(device)\n            lengths = [len(c['messages']) for c in batch]\n\n            final_pred = model(messages, ling_features, senders, receivers, seasons, years,\n                              game_scores, game_score_deltas, lengths)\n            loss = criterion(final_pred.squeeze(-1), sender_labels)\n            mask = (sender_labels != -1)\n            loss = (loss * mask).sum() / (mask.sum() + 1e-8)\n            total_loss += loss.item()\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n\n        avg_train_loss = total_loss / (len(train_data) / batch_size)\n\n        # Validate\n        val_loss, val_metrics = evaluate_batch(val_data)\n        print(f\"\\n=== Epoch {epoch+1}/{epochs} Metrics ===\")\n        print(f\"Train Loss: {avg_train_loss:.4f}\")\n        print(f\"Validation Loss: {val_loss:.4f}\")\n        print(\"\\nPer-Class Metrics:\")\n        print(f\"True Precision: {val_metrics['True_precision']:.4f}, False Precision: {val_metrics['False_precision']:.4f}\")\n        print(f\"True Recall: {val_metrics['True_recall']:.4f}, False Recall: {val_metrics['False_recall']:.4f}\")\n        print(f\"True F1: {val_metrics['True_fscore']:.4f}, False F1: {val_metrics['False_fscore']:.4f}\")\n        print(\"\\nAggregated Metrics:\")\n        print(f\"Micro F1: {val_metrics['micro_fscore']:.4f}, Macro F1: {val_metrics['macro_fscore']:.4f}\")\n        print(f\"Confusion Matrix:\\n{val_metrics['confusion_matrix']}\")\n\n        # Save epoch checkpoint if criteria met\n       # Save epoch checkpoint if criteria met\n        if val_metrics['macro_fscore'] > 0.55 or val_metrics['False_fscore'] > 0.18:\n            checkpoint_state = {\n                'epoch': epoch + 1,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'scheduler_state_dict': scheduler.state_dict(),\n                'val_loss': val_loss,\n                'metrics': val_metrics,\n                'pos_weight': pos_weight_val\n            }\n            checkpoint_filename = f'checkpoint_epoch_{epoch+1}_macroF1_{val_metrics[\"macro_fscore\"]:.4f}_falseF1_{val_metrics[\"False_fscore\"]:.4f}.pt'\n            torch.save(checkpoint_state, os.path.join(checkpoint_dir, checkpoint_filename))\n            print(f\"Saved checkpoint {checkpoint_filename} (False F1: {val_metrics['False_fscore']:.4f}, Macro F1: {val_metrics['macro_fscore']:.4f})\")\n\n# Update best_checkpoint.pt based on Macro F1 (or False F1 as tiebreaker)\n    \n        if val_metrics['macro_fscore'] > best_macro_f1 or \\\n           (val_metrics['macro_fscore'] == best_macro_f1 and val_metrics['False_fscore'] > best_false_f1):\n            best_macro_f1 = val_metrics['macro_fscore']\n            best_false_f1 = val_metrics['False_fscore']\n            best_val_loss = val_loss\n            best_metrics = val_metrics\n            best_model_state = model.state_dict().copy()\n            torch.save({\n                'epoch': epoch + 1,\n                'model_state_dict': best_model_state,\n                'optimizer_state_dict': optimizer.state_dict(),\n                'scheduler_state_dict': scheduler.state_dict(),\n                'val_loss': best_val_loss,\n                'metrics': best_metrics,\n                'pos_weight': pos_weight_val\n            }, os.path.join(checkpoint_dir, 'best_checkpoint.pt'))\n            print(f\"Updated best_checkpoint.pt with Macro F1: {best_macro_f1:.4f}, False F1: {best_false_f1:.4f}\")\n    # Load best model for final evaluation\n    model.load_state_dict(best_model_state)\n    test_loss, test_metrics = evaluate_batch(test_data)\n    print(f\"\\n=== Final Test Metrics ===\")\n    print(f\"Test Loss: {test_loss:.4f}\")\n    print(\"\\nPer-Class Metrics:\")\n    print(f\"True Precision: {test_metrics['True_precision']:.4f}, False Precision: {test_metrics['False_precision']:.4f}\")\n    print(f\"True Recall: {test_metrics['True_recall']:.4f}, False Recall: {test_metrics['False_recall']:.4f}\")\n    print(f\"True F1: {test_metrics['True_fscore']:.4f}, False F1: {test_metrics['False_fscore']:.4f}\")\n    print(\"\\nAggregated Metrics:\")\n    print(f\"Micro F1: {test_metrics['micro_fscore']:.4f}, Macro F1: {test_metrics['macro_fscore']:.4f}\")\n    print(f\"Confusion Matrix:\\n{test_metrics['confusion_matrix']}\")\n    return {'test_loss': test_loss, 'test_metrics': test_metrics, 'training_loss': avg_train_loss,\n            'validation_loss': val_loss, 'best_validation_loss': best_val_loss,\n            'best_validation_metrics': best_metrics}\n\n# Grid Search for Hyperparameters\ndef grid_search_hyperparams(train_data, val_data, test_data, num_countries, num_seasons, num_years, \n                           use_ling_features=True, epochs=15, patience=3):\n    param_grid = {'lr': [0.00005, 0.0001, 0.0002], 'batch_size': [4, 8]}\n    best_macro_f1 = 0\n    best_params = None\n    best_results = None\n    \n    for lr, batch_size in itertools.product(param_grid['lr'], param_grid['batch_size']):\n        logger.info(f\"Testing lr={lr}, batch_size={batch_size}\")\n        model = EnhancedDeceptionDetector(\n            num_countries=num_countries, num_seasons=num_seasons, num_years=num_years,\n            sentence_emb_dim=384, ling_feature_dim=6 if use_ling_features else 0,\n            country_emb_dim=16, season_emb_dim=8, year_emb_dim=8, hidden_dim=64, dropout=0.4\n        ).to(device)\n        \n        results = train_and_evaluate(model, train_data, val_data, test_data,\n                                     epochs=epochs, batch_size=batch_size, lr=lr, patience=patience)\n        \n        macro_f1 = results['best_validation_metrics']['macro_fscore']\n        logger.info(f\"lr={lr}, batch_size={batch_size}, Validation Macro F1: {macro_f1:.4f}\")\n        \n        if macro_f1 > best_macro_f1:\n            best_macro_f1 = macro_f1\n            best_params = {'lr': lr, 'batch_size': batch_size}\n            best_results = results\n    \n    return best_params, best_results\n\n# Oversample Lie Conversations\ndef oversample_lies(data, oversample_factor=2):\n    lie_convs = [conv for conv in data if any(l == 1 for l in conv['sender_labels'])]\n    oversampled = data + lie_convs * (oversample_factor - 1)\n    logger.info(f\"Oversampled: {len(data)} -> {len(oversampled)} conversations\")\n    return oversampled\n\n# Main Execution\nif __name__ == \"__main__\":\n    train_file = \"/kaggle/input/dataset-deception/train.jsonl\"\n    val_file = \"/kaggle/input/dataset-deception/validation.jsonl\"\n    test_file = \"/kaggle/input/dataset-deception/test.jsonl\"\n    \n    use_ling_features = True\n    train_data, country_map, season_map, year_map, ling_stats = preprocess_data(train_file, use_ling_features=use_ling_features)\n    val_data, _, _, _, _ = preprocess_data(val_file, country_map, season_map, year_map, use_ling_features=use_ling_features, ling_stats=ling_stats)\n    test_data, _, _, _, _ = preprocess_data(test_file, country_map, season_map, year_map, use_ling_features=use_ling_features, ling_stats=ling_stats)\n    \n    train_data = oversample_lies(train_data, oversample_factor=2)\n    \n    num_countries = len(country_map)\n    num_seasons = len(season_map)\n    num_years = len(year_map)\n    best_params, results = grid_search_hyperparams(\n        train_data, val_data, test_data, num_countries, num_seasons, num_years,\n        use_ling_features=use_ling_features, epochs=15, patience=3\n    )\n    \n    logger.info(f\"Best parameters: lr={best_params['lr']}, batch_size={best_params['batch_size']}\")\n    \n    print(\"\\n=== Per-Class Metrics (for 'True' and 'False' classes) ===\")\n    print(\"Precision\")\n    print(f\"True_precision: {results['test_metrics']['True_precision']:.4f}\")\n    print(f\"False_precision: {results['test_metrics']['False_precision']:.4f}\")\n    print(\"Recall\")\n    print(f\"True_recall: {results['test_metrics']['True_recall']:.4f}\")\n    print(f\"False_recall: {results['test_metrics']['False_recall']:.4f}\")\n    print(\"F1-Score\")\n    print(f\"True_fscore: {results['test_metrics']['True_fscore']:.4f}\")\n    print(f\"False_fscore: {results['test_metrics']['False_fscore']:.4f}\")\n    \n    print(\"\\n📊 Micro-Averaged Metrics\")\n    print(f\"micro_precision: {results['test_metrics']['micro_precision']:.4f}\")\n    print(f\"micro_recall: {results['test_metrics']['micro_recall']:.4f}\")\n    print(f\"micro_fscore: {results['test_metrics']['micro_fscore']:.4f}\")\n    \n    print(\"\\n📈 Macro-Averaged Metrics\")\n    print(f\"macro_precision: {results['test_metrics']['macro_precision']:.4f}\")\n    print(f\"macro_recall: {results['test_metrics']['macro_recall']:.4f}\")\n    print(f\"macro_fscore: {results['test_metrics']['macro_fscore']:.4f}\")\n    \n    print(\"\\n🧠 Loss\")\n    print(f\"training_loss: {results['training_loss']:.4f}\")\n    print(f\"validation_loss: {results['validation_loss']:.4f}\")\n    print(f\"best_validation_loss: {results['best_validation_loss']:.4f}\")\n    print(f\"test_loss: {results['test_loss']:.4f}\")\n    \n    print(\"\\n🧪 Best Validation Metrics\")\n    for metric in ['True_precision', 'False_precision', 'True_recall', 'False_recall',\n                  'True_fscore', 'False_fscore', 'micro_precision', 'micro_recall',\n                  'micro_fscore', 'macro_precision', 'macro_recall', 'macro_fscore']:\n        print(f\"best_validation_{metric}: {results['best_validation_metrics'][metric]:.4f}\")\n    \n    print(\"\\n🔍 Test Confusion Matrix\")\n    print(results['test_metrics']['confusion_matrix'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T07:49:36.917640Z","iopub.execute_input":"2025-04-15T07:49:36.917915Z","iopub.status.idle":"2025-04-15T08:07:18.411959Z","shell.execute_reply.started":"2025-04-15T07:49:36.917895Z","shell.execute_reply":"2025-04-15T08:07:18.411169Z"}},"outputs":[{"name":"stderr","text":"Processing conversations: 100%|██████████| 189/189 [00:53<00:00,  3.57it/s]\nProcessing conversations: 100%|██████████| 21/21 [00:05<00:00,  3.97it/s]\nProcessing conversations: 100%|██████████| 42/42 [00:10<00:00,  3.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n=== Epoch 1/15 Metrics ===\nTrain Loss: 0.0902\nValidation Loss: 0.0804\n\nPer-Class Metrics:\nTrue Precision: 0.9529, False Precision: 0.0103\nTrue Recall: 0.7890, False Recall: 0.0536\nTrue F1: 0.8632, False F1: 0.0173\n\nAggregated Metrics:\nMicro F1: 0.7599, Macro F1: 0.4403\nConfusion Matrix:\n[[   3   53]\n [ 287 1073]]\nUpdated best_checkpoint.pt with Macro F1: 0.4403, False F1: 0.0173\n\n=== Epoch 2/15 Metrics ===\nTrain Loss: 0.0858\nValidation Loss: 0.0777\n\nPer-Class Metrics:\nTrue Precision: 0.9622, False Precision: 0.2000\nTrue Recall: 0.9912, False Recall: 0.0536\nTrue F1: 0.9765, False F1: 0.0845\n\nAggregated Metrics:\nMicro F1: 0.9541, Macro F1: 0.5305\nConfusion Matrix:\n[[   3   53]\n [  12 1348]]\nUpdated best_checkpoint.pt with Macro F1: 0.5305, False F1: 0.0845\n\n=== Epoch 3/15 Metrics ===\nTrain Loss: 0.0840\nValidation Loss: 0.0758\n\nPer-Class Metrics:\nTrue Precision: 0.9657, False Precision: 0.2000\nTrue Recall: 0.9735, False Recall: 0.1607\nTrue F1: 0.9696, False F1: 0.1782\n\nAggregated Metrics:\nMicro F1: 0.9414, Macro F1: 0.5739\nConfusion Matrix:\n[[   9   47]\n [  36 1324]]\nSaved checkpoint checkpoint_epoch_3_macroF1_0.5739_falseF1_0.1782.pt (False F1: 0.1782, Macro F1: 0.5739)\nUpdated best_checkpoint.pt with Macro F1: 0.5739, False F1: 0.1782\n\n=== Epoch 4/15 Metrics ===\nTrain Loss: 0.0829\nValidation Loss: 0.0746\n\nPer-Class Metrics:\nTrue Precision: 0.9657, False Precision: 0.2000\nTrue Recall: 0.9735, False Recall: 0.1607\nTrue F1: 0.9696, False F1: 0.1782\n\nAggregated Metrics:\nMicro F1: 0.9414, Macro F1: 0.5739\nConfusion Matrix:\n[[   9   47]\n [  36 1324]]\nSaved checkpoint checkpoint_epoch_4_macroF1_0.5739_falseF1_0.1782.pt (False F1: 0.1782, Macro F1: 0.5739)\n\n=== Epoch 5/15 Metrics ===\nTrain Loss: 0.0819\nValidation Loss: 0.0739\n\nPer-Class Metrics:\nTrue Precision: 0.9657, False Precision: 0.2000\nTrue Recall: 0.9735, False Recall: 0.1607\nTrue F1: 0.9696, False F1: 0.1782\n\nAggregated Metrics:\nMicro F1: 0.9414, Macro F1: 0.5739\nConfusion Matrix:\n[[   9   47]\n [  36 1324]]\nSaved checkpoint checkpoint_epoch_5_macroF1_0.5739_falseF1_0.1782.pt (False F1: 0.1782, Macro F1: 0.5739)\n\n=== Epoch 6/15 Metrics ===\nTrain Loss: 0.0813\nValidation Loss: 0.0734\n\nPer-Class Metrics:\nTrue Precision: 0.9680, False Precision: 0.1781\nTrue Recall: 0.9559, False Recall: 0.2321\nTrue F1: 0.9619, False F1: 0.2016\n\nAggregated Metrics:\nMicro F1: 0.9273, Macro F1: 0.5817\nConfusion Matrix:\n[[  13   43]\n [  60 1300]]\nSaved checkpoint checkpoint_epoch_6_macroF1_0.5817_falseF1_0.2016.pt (False F1: 0.2016, Macro F1: 0.5817)\nUpdated best_checkpoint.pt with Macro F1: 0.5817, False F1: 0.2016\n\n=== Epoch 7/15 Metrics ===\nTrain Loss: 0.0807\nValidation Loss: 0.0731\n\nPer-Class Metrics:\nTrue Precision: 0.9680, False Precision: 0.1781\nTrue Recall: 0.9559, False Recall: 0.2321\nTrue F1: 0.9619, False F1: 0.2016\n\nAggregated Metrics:\nMicro F1: 0.9273, Macro F1: 0.5817\nConfusion Matrix:\n[[  13   43]\n [  60 1300]]\nSaved checkpoint checkpoint_epoch_7_macroF1_0.5817_falseF1_0.2016.pt (False F1: 0.2016, Macro F1: 0.5817)\n\n=== Epoch 8/15 Metrics ===\nTrain Loss: 0.0798\nValidation Loss: 0.0728\n\nPer-Class Metrics:\nTrue Precision: 0.9678, False Precision: 0.1585\nTrue Recall: 0.9493, False Recall: 0.2321\nTrue F1: 0.9584, False F1: 0.1884\n\nAggregated Metrics:\nMicro F1: 0.9209, Macro F1: 0.5734\nConfusion Matrix:\n[[  13   43]\n [  69 1291]]\nSaved checkpoint checkpoint_epoch_8_macroF1_0.5734_falseF1_0.1884.pt (False F1: 0.1884, Macro F1: 0.5734)\n\n=== Epoch 9/15 Metrics ===\nTrain Loss: 0.0796\nValidation Loss: 0.0727\n\nPer-Class Metrics:\nTrue Precision: 0.9678, False Precision: 0.1585\nTrue Recall: 0.9493, False Recall: 0.2321\nTrue F1: 0.9584, False F1: 0.1884\n\nAggregated Metrics:\nMicro F1: 0.9209, Macro F1: 0.5734\nConfusion Matrix:\n[[  13   43]\n [  69 1291]]\nSaved checkpoint checkpoint_epoch_9_macroF1_0.5734_falseF1_0.1884.pt (False F1: 0.1884, Macro F1: 0.5734)\n\n=== Epoch 10/15 Metrics ===\nTrain Loss: 0.0791\nValidation Loss: 0.0725\n\nPer-Class Metrics:\nTrue Precision: 0.9678, False Precision: 0.1585\nTrue Recall: 0.9493, False Recall: 0.2321\nTrue F1: 0.9584, False F1: 0.1884\n\nAggregated Metrics:\nMicro F1: 0.9209, Macro F1: 0.5734\nConfusion Matrix:\n[[  13   43]\n [  69 1291]]\nSaved checkpoint checkpoint_epoch_10_macroF1_0.5734_falseF1_0.1884.pt (False F1: 0.1884, Macro F1: 0.5734)\n\n=== Epoch 11/15 Metrics ===\nTrain Loss: 0.0788\nValidation Loss: 0.0724\n\nPer-Class Metrics:\nTrue Precision: 0.9641, False Precision: 0.1346\nTrue Recall: 0.9669, False Recall: 0.1250\nTrue F1: 0.9655, False F1: 0.1296\n\nAggregated Metrics:\nMicro F1: 0.9336, Macro F1: 0.5476\nConfusion Matrix:\n[[   7   49]\n [  45 1315]]\n\n=== Epoch 12/15 Metrics ===\nTrain Loss: 0.0784\nValidation Loss: 0.0723\n\nPer-Class Metrics:\nTrue Precision: 0.9638, False Precision: 0.0899\nTrue Recall: 0.9404, False Recall: 0.1429\nTrue F1: 0.9520, False F1: 0.1103\n\nAggregated Metrics:\nMicro F1: 0.9089, Macro F1: 0.5312\nConfusion Matrix:\n[[   8   48]\n [  81 1279]]\n\n=== Epoch 13/15 Metrics ===\nTrain Loss: 0.0777\nValidation Loss: 0.0722\n\nPer-Class Metrics:\nTrue Precision: 0.9638, False Precision: 0.0899\nTrue Recall: 0.9404, False Recall: 0.1429\nTrue F1: 0.9520, False F1: 0.1103\n\nAggregated Metrics:\nMicro F1: 0.9089, Macro F1: 0.5312\nConfusion Matrix:\n[[   8   48]\n [  81 1279]]\n\n=== Epoch 14/15 Metrics ===\nTrain Loss: 0.0776\nValidation Loss: 0.0722\n\nPer-Class Metrics:\nTrue Precision: 0.9638, False Precision: 0.0899\nTrue Recall: 0.9404, False Recall: 0.1429\nTrue F1: 0.9520, False F1: 0.1103\n\nAggregated Metrics:\nMicro F1: 0.9089, Macro F1: 0.5312\nConfusion Matrix:\n[[   8   48]\n [  81 1279]]\n\n=== Epoch 15/15 Metrics ===\nTrain Loss: 0.0771\nValidation Loss: 0.0722\n\nPer-Class Metrics:\nTrue Precision: 0.9638, False Precision: 0.0899\nTrue Recall: 0.9404, False Recall: 0.1429\nTrue F1: 0.9520, False F1: 0.1103\n\nAggregated Metrics:\nMicro F1: 0.9089, Macro F1: 0.5312\nConfusion Matrix:\n[[   8   48]\n [  81 1279]]\n\n=== Final Test Metrics ===\nTest Loss: 0.1252\n\nPer-Class Metrics:\nTrue Precision: 0.9181, False Precision: 0.1157\nTrue Recall: 0.8381, False Recall: 0.2208\nTrue F1: 0.8763, False F1: 0.1519\n\nAggregated Metrics:\nMicro F1: 0.7840, Macro F1: 0.5141\nConfusion Matrix:\n[[  53  187]\n [ 405 2096]]\n\n=== Epoch 1/15 Metrics ===\nTrain Loss: 0.0907\nValidation Loss: 0.0811\n\nPer-Class Metrics:\nTrue Precision: 0.9605, False Precision: 0.0000\nTrue Recall: 1.0000, False Recall: 0.0000\nTrue F1: 0.9798, False F1: 0.0000\n\nAggregated Metrics:\nMicro F1: 0.9605, Macro F1: 0.4899\nConfusion Matrix:\n[[   0   56]\n [   0 1360]]\nUpdated best_checkpoint.pt with Macro F1: 0.4899, False F1: 0.0000\n\n=== Epoch 2/15 Metrics ===\nTrain Loss: 0.0832\nValidation Loss: 0.0779\n\nPer-Class Metrics:\nTrue Precision: 0.9639, False Precision: 0.1228\nTrue Recall: 0.9632, False Recall: 0.1250\nTrue F1: 0.9636, False F1: 0.1239\n\nAggregated Metrics:\nMicro F1: 0.9301, Macro F1: 0.5437\nConfusion Matrix:\n[[   7   49]\n [  50 1310]]\nUpdated best_checkpoint.pt with Macro F1: 0.5437, False F1: 0.1239\n\n=== Epoch 3/15 Metrics ===\nTrain Loss: 0.0818\nValidation Loss: 0.0768\n\nPer-Class Metrics:\nTrue Precision: 0.9639, False Precision: 0.1228\nTrue Recall: 0.9632, False Recall: 0.1250\nTrue F1: 0.9636, False F1: 0.1239\n\nAggregated Metrics:\nMicro F1: 0.9301, Macro F1: 0.5437\nConfusion Matrix:\n[[   7   49]\n [  50 1310]]\n\n=== Epoch 4/15 Metrics ===\nTrain Loss: 0.0811\nValidation Loss: 0.0761\n\nPer-Class Metrics:\nTrue Precision: 0.9657, False Precision: 0.1333\nTrue Recall: 0.9522, False Recall: 0.1786\nTrue F1: 0.9589, False F1: 0.1527\n\nAggregated Metrics:\nMicro F1: 0.9216, Macro F1: 0.5558\nConfusion Matrix:\n[[  10   46]\n [  65 1295]]\nSaved checkpoint checkpoint_epoch_4_macroF1_0.5558_falseF1_0.1527.pt (False F1: 0.1527, Macro F1: 0.5558)\nUpdated best_checkpoint.pt with Macro F1: 0.5558, False F1: 0.1527\n\n=== Epoch 5/15 Metrics ===\nTrain Loss: 0.0803\nValidation Loss: 0.0756\n\nPer-Class Metrics:\nTrue Precision: 0.9657, False Precision: 0.1333\nTrue Recall: 0.9522, False Recall: 0.1786\nTrue F1: 0.9589, False F1: 0.1527\n\nAggregated Metrics:\nMicro F1: 0.9216, Macro F1: 0.5558\nConfusion Matrix:\n[[  10   46]\n [  65 1295]]\nSaved checkpoint checkpoint_epoch_5_macroF1_0.5558_falseF1_0.1527.pt (False F1: 0.1527, Macro F1: 0.5558)\n\n=== Epoch 6/15 Metrics ===\nTrain Loss: 0.0801\nValidation Loss: 0.0751\n\nPer-Class Metrics:\nTrue Precision: 0.9654, False Precision: 0.1136\nTrue Recall: 0.9426, False Recall: 0.1786\nTrue F1: 0.9539, False F1: 0.1389\n\nAggregated Metrics:\nMicro F1: 0.9124, Macro F1: 0.5464\nConfusion Matrix:\n[[  10   46]\n [  78 1282]]\n\n=== Epoch 7/15 Metrics ===\nTrain Loss: 0.0802\nValidation Loss: 0.0748\n\nPer-Class Metrics:\nTrue Precision: 0.9654, False Precision: 0.1136\nTrue Recall: 0.9426, False Recall: 0.1786\nTrue F1: 0.9539, False F1: 0.1389\n\nAggregated Metrics:\nMicro F1: 0.9124, Macro F1: 0.5464\nConfusion Matrix:\n[[  10   46]\n [  78 1282]]\n\n=== Epoch 8/15 Metrics ===\nTrain Loss: 0.0793\nValidation Loss: 0.0746\n\nPer-Class Metrics:\nTrue Precision: 0.9654, False Precision: 0.1136\nTrue Recall: 0.9426, False Recall: 0.1786\nTrue F1: 0.9539, False F1: 0.1389\n\nAggregated Metrics:\nMicro F1: 0.9124, Macro F1: 0.5464\nConfusion Matrix:\n[[  10   46]\n [  78 1282]]\n\n=== Epoch 9/15 Metrics ===\nTrain Loss: 0.0789\nValidation Loss: 0.0745\n\nPer-Class Metrics:\nTrue Precision: 0.9654, False Precision: 0.1136\nTrue Recall: 0.9426, False Recall: 0.1786\nTrue F1: 0.9539, False F1: 0.1389\n\nAggregated Metrics:\nMicro F1: 0.9124, Macro F1: 0.5464\nConfusion Matrix:\n[[  10   46]\n [  78 1282]]\n\n=== Epoch 10/15 Metrics ===\nTrain Loss: 0.0786\nValidation Loss: 0.0743\n\nPer-Class Metrics:\nTrue Precision: 0.9654, False Precision: 0.1136\nTrue Recall: 0.9426, False Recall: 0.1786\nTrue F1: 0.9539, False F1: 0.1389\n\nAggregated Metrics:\nMicro F1: 0.9124, Macro F1: 0.5464\nConfusion Matrix:\n[[  10   46]\n [  78 1282]]\n\n=== Epoch 11/15 Metrics ===\nTrain Loss: 0.0786\nValidation Loss: 0.0741\n\nPer-Class Metrics:\nTrue Precision: 0.9678, False Precision: 0.1239\nTrue Recall: 0.9272, False Recall: 0.2500\nTrue F1: 0.9471, False F1: 0.1657\n\nAggregated Metrics:\nMicro F1: 0.9004, Macro F1: 0.5564\nConfusion Matrix:\n[[  14   42]\n [  99 1261]]\nSaved checkpoint checkpoint_epoch_11_macroF1_0.5564_falseF1_0.1657.pt (False F1: 0.1657, Macro F1: 0.5564)\nUpdated best_checkpoint.pt with Macro F1: 0.5564, False F1: 0.1657\n\n=== Epoch 12/15 Metrics ===\nTrain Loss: 0.0784\nValidation Loss: 0.0740\n\nPer-Class Metrics:\nTrue Precision: 0.9678, False Precision: 0.1239\nTrue Recall: 0.9272, False Recall: 0.2500\nTrue F1: 0.9471, False F1: 0.1657\n\nAggregated Metrics:\nMicro F1: 0.9004, Macro F1: 0.5564\nConfusion Matrix:\n[[  14   42]\n [  99 1261]]\nSaved checkpoint checkpoint_epoch_12_macroF1_0.5564_falseF1_0.1657.pt (False F1: 0.1657, Macro F1: 0.5564)\n\n=== Epoch 13/15 Metrics ===\nTrain Loss: 0.0776\nValidation Loss: 0.0739\n\nPer-Class Metrics:\nTrue Precision: 0.9678, False Precision: 0.1239\nTrue Recall: 0.9272, False Recall: 0.2500\nTrue F1: 0.9471, False F1: 0.1657\n\nAggregated Metrics:\nMicro F1: 0.9004, Macro F1: 0.5564\nConfusion Matrix:\n[[  14   42]\n [  99 1261]]\nSaved checkpoint checkpoint_epoch_13_macroF1_0.5564_falseF1_0.1657.pt (False F1: 0.1657, Macro F1: 0.5564)\n\n=== Epoch 14/15 Metrics ===\nTrain Loss: 0.0774\nValidation Loss: 0.0738\n\nPer-Class Metrics:\nTrue Precision: 0.9675, False Precision: 0.1148\nTrue Recall: 0.9206, False Recall: 0.2500\nTrue F1: 0.9435, False F1: 0.1573\n\nAggregated Metrics:\nMicro F1: 0.8941, Macro F1: 0.5504\nConfusion Matrix:\n[[  14   42]\n [ 108 1252]]\nSaved checkpoint checkpoint_epoch_14_macroF1_0.5504_falseF1_0.1573.pt (False F1: 0.1573, Macro F1: 0.5504)\n\n=== Epoch 15/15 Metrics ===\nTrain Loss: 0.0774\nValidation Loss: 0.0737\n\nPer-Class Metrics:\nTrue Precision: 0.9675, False Precision: 0.1148\nTrue Recall: 0.9206, False Recall: 0.2500\nTrue F1: 0.9435, False F1: 0.1573\n\nAggregated Metrics:\nMicro F1: 0.8941, Macro F1: 0.5504\nConfusion Matrix:\n[[  14   42]\n [ 108 1252]]\nSaved checkpoint checkpoint_epoch_15_macroF1_0.5504_falseF1_0.1573.pt (False F1: 0.1573, Macro F1: 0.5504)\n\n=== Final Test Metrics ===\nTest Loss: 0.1334\n\nPer-Class Metrics:\nTrue Precision: 0.9079, False Precision: 0.0179\nTrue Recall: 0.9340, False Recall: 0.0125\nTrue F1: 0.9208, False F1: 0.0147\n\nAggregated Metrics:\nMicro F1: 0.8533, Macro F1: 0.4677\nConfusion Matrix:\n[[   3  237]\n [ 165 2336]]\n\n=== Epoch 1/15 Metrics ===\nTrain Loss: 0.0884\nValidation Loss: 0.0772\n\nPer-Class Metrics:\nTrue Precision: 0.9602, False Precision: 0.0376\nTrue Recall: 0.9059, False Recall: 0.0893\nTrue F1: 0.9323, False F1: 0.0529\n\nAggregated Metrics:\nMicro F1: 0.8736, Macro F1: 0.4926\nConfusion Matrix:\n[[   5   51]\n [ 128 1232]]\nUpdated best_checkpoint.pt with Macro F1: 0.4926, False F1: 0.0529\n\n=== Epoch 2/15 Metrics ===\nTrain Loss: 0.0839\nValidation Loss: 0.0747\n\nPer-Class Metrics:\nTrue Precision: 0.9680, False Precision: 0.1781\nTrue Recall: 0.9559, False Recall: 0.2321\nTrue F1: 0.9619, False F1: 0.2016\n\nAggregated Metrics:\nMicro F1: 0.9273, Macro F1: 0.5817\nConfusion Matrix:\n[[  13   43]\n [  60 1300]]\nSaved checkpoint checkpoint_epoch_2_macroF1_0.5817_falseF1_0.2016.pt (False F1: 0.2016, Macro F1: 0.5817)\nUpdated best_checkpoint.pt with Macro F1: 0.5817, False F1: 0.2016\n\n=== Epoch 3/15 Metrics ===\nTrain Loss: 0.0813\nValidation Loss: 0.0734\n\nPer-Class Metrics:\nTrue Precision: 0.9678, False Precision: 0.1585\nTrue Recall: 0.9493, False Recall: 0.2321\nTrue F1: 0.9584, False F1: 0.1884\n\nAggregated Metrics:\nMicro F1: 0.9209, Macro F1: 0.5734\nConfusion Matrix:\n[[  13   43]\n [  69 1291]]\nSaved checkpoint checkpoint_epoch_3_macroF1_0.5734_falseF1_0.1884.pt (False F1: 0.1884, Macro F1: 0.5734)\n\n=== Epoch 4/15 Metrics ===\nTrain Loss: 0.0800\nValidation Loss: 0.0727\n\nPer-Class Metrics:\nTrue Precision: 0.9678, False Precision: 0.1585\nTrue Recall: 0.9493, False Recall: 0.2321\nTrue F1: 0.9584, False F1: 0.1884\n\nAggregated Metrics:\nMicro F1: 0.9209, Macro F1: 0.5734\nConfusion Matrix:\n[[  13   43]\n [  69 1291]]\nSaved checkpoint checkpoint_epoch_4_macroF1_0.5734_falseF1_0.1884.pt (False F1: 0.1884, Macro F1: 0.5734)\n\n=== Epoch 5/15 Metrics ===\nTrain Loss: 0.0794\nValidation Loss: 0.0723\n\nPer-Class Metrics:\nTrue Precision: 0.9678, False Precision: 0.1585\nTrue Recall: 0.9493, False Recall: 0.2321\nTrue F1: 0.9584, False F1: 0.1884\n\nAggregated Metrics:\nMicro F1: 0.9209, Macro F1: 0.5734\nConfusion Matrix:\n[[  13   43]\n [  69 1291]]\nSaved checkpoint checkpoint_epoch_5_macroF1_0.5734_falseF1_0.1884.pt (False F1: 0.1884, Macro F1: 0.5734)\n\n=== Epoch 6/15 Metrics ===\nTrain Loss: 0.0785\nValidation Loss: 0.0722\n\nPer-Class Metrics:\nTrue Precision: 0.9678, False Precision: 0.1585\nTrue Recall: 0.9493, False Recall: 0.2321\nTrue F1: 0.9584, False F1: 0.1884\n\nAggregated Metrics:\nMicro F1: 0.9209, Macro F1: 0.5734\nConfusion Matrix:\n[[  13   43]\n [  69 1291]]\nSaved checkpoint checkpoint_epoch_6_macroF1_0.5734_falseF1_0.1884.pt (False F1: 0.1884, Macro F1: 0.5734)\n\n=== Epoch 7/15 Metrics ===\nTrain Loss: 0.0782\nValidation Loss: 0.0722\n\nPer-Class Metrics:\nTrue Precision: 0.9678, False Precision: 0.1585\nTrue Recall: 0.9493, False Recall: 0.2321\nTrue F1: 0.9584, False F1: 0.1884\n\nAggregated Metrics:\nMicro F1: 0.9209, Macro F1: 0.5734\nConfusion Matrix:\n[[  13   43]\n [  69 1291]]\nSaved checkpoint checkpoint_epoch_7_macroF1_0.5734_falseF1_0.1884.pt (False F1: 0.1884, Macro F1: 0.5734)\n\n=== Epoch 8/15 Metrics ===\nTrain Loss: 0.0770\nValidation Loss: 0.0722\n\nPer-Class Metrics:\nTrue Precision: 0.9641, False Precision: 0.1346\nTrue Recall: 0.9669, False Recall: 0.1250\nTrue F1: 0.9655, False F1: 0.1296\n\nAggregated Metrics:\nMicro F1: 0.9336, Macro F1: 0.5476\nConfusion Matrix:\n[[   7   49]\n [  45 1315]]\n\n=== Epoch 9/15 Metrics ===\nTrain Loss: 0.0770\nValidation Loss: 0.0723\n\nPer-Class Metrics:\nTrue Precision: 0.9641, False Precision: 0.1346\nTrue Recall: 0.9669, False Recall: 0.1250\nTrue F1: 0.9655, False F1: 0.1296\n\nAggregated Metrics:\nMicro F1: 0.9336, Macro F1: 0.5476\nConfusion Matrix:\n[[   7   49]\n [  45 1315]]\n\n=== Epoch 10/15 Metrics ===\nTrain Loss: 0.0762\nValidation Loss: 0.0723\n\nPer-Class Metrics:\nTrue Precision: 0.9641, False Precision: 0.1346\nTrue Recall: 0.9669, False Recall: 0.1250\nTrue F1: 0.9655, False F1: 0.1296\n\nAggregated Metrics:\nMicro F1: 0.9336, Macro F1: 0.5476\nConfusion Matrix:\n[[   7   49]\n [  45 1315]]\n\n=== Epoch 11/15 Metrics ===\nTrain Loss: 0.0756\nValidation Loss: 0.0723\n\nPer-Class Metrics:\nTrue Precision: 0.9641, False Precision: 0.1346\nTrue Recall: 0.9669, False Recall: 0.1250\nTrue F1: 0.9655, False F1: 0.1296\n\nAggregated Metrics:\nMicro F1: 0.9336, Macro F1: 0.5476\nConfusion Matrix:\n[[   7   49]\n [  45 1315]]\n\n=== Epoch 12/15 Metrics ===\nTrain Loss: 0.0751\nValidation Loss: 0.0726\n\nPer-Class Metrics:\nTrue Precision: 0.9635, False Precision: 0.0946\nTrue Recall: 0.9507, False Recall: 0.1250\nTrue F1: 0.9571, False F1: 0.1077\n\nAggregated Metrics:\nMicro F1: 0.9181, Macro F1: 0.5324\nConfusion Matrix:\n[[   7   49]\n [  67 1293]]\n\n=== Epoch 13/15 Metrics ===\nTrain Loss: 0.0744\nValidation Loss: 0.0729\n\nPer-Class Metrics:\nTrue Precision: 0.9635, False Precision: 0.0946\nTrue Recall: 0.9507, False Recall: 0.1250\nTrue F1: 0.9571, False F1: 0.1077\n\nAggregated Metrics:\nMicro F1: 0.9181, Macro F1: 0.5324\nConfusion Matrix:\n[[   7   49]\n [  67 1293]]\n\n=== Epoch 14/15 Metrics ===\nTrain Loss: 0.0734\nValidation Loss: 0.0734\n\nPer-Class Metrics:\nTrue Precision: 0.9635, False Precision: 0.0946\nTrue Recall: 0.9507, False Recall: 0.1250\nTrue F1: 0.9571, False F1: 0.1077\n\nAggregated Metrics:\nMicro F1: 0.9181, Macro F1: 0.5324\nConfusion Matrix:\n[[   7   49]\n [  67 1293]]\n\n=== Epoch 15/15 Metrics ===\nTrain Loss: 0.0734\nValidation Loss: 0.0737\n\nPer-Class Metrics:\nTrue Precision: 0.9632, False Precision: 0.0814\nTrue Recall: 0.9419, False Recall: 0.1250\nTrue F1: 0.9524, False F1: 0.0986\n\nAggregated Metrics:\nMicro F1: 0.9096, Macro F1: 0.5255\nConfusion Matrix:\n[[   7   49]\n [  79 1281]]\n\n=== Final Test Metrics ===\nTest Loss: 0.1231\n\nPer-Class Metrics:\nTrue Precision: 0.9272, False Precision: 0.1139\nTrue Recall: 0.6517, False Recall: 0.4667\nTrue F1: 0.7654, False F1: 0.1832\n\nAggregated Metrics:\nMicro F1: 0.6355, Macro F1: 0.4743\nConfusion Matrix:\n[[ 112  128]\n [ 871 1630]]\n\n=== Epoch 1/15 Metrics ===\nTrain Loss: 0.0932\nValidation Loss: 0.0792\n\nPer-Class Metrics:\nTrue Precision: 0.9612, False Precision: 0.0419\nTrue Recall: 0.7647, False Recall: 0.2500\nTrue F1: 0.8518, False F1: 0.0718\n\nAggregated Metrics:\nMicro F1: 0.7444, Macro F1: 0.4618\nConfusion Matrix:\n[[  14   42]\n [ 320 1040]]\nUpdated best_checkpoint.pt with Macro F1: 0.4618, False F1: 0.0718\n\n=== Epoch 2/15 Metrics ===\nTrain Loss: 0.0830\nValidation Loss: 0.0767\n\nPer-Class Metrics:\nTrue Precision: 0.9599, False Precision: 0.0294\nTrue Recall: 0.9515, False Recall: 0.0357\nTrue F1: 0.9557, False F1: 0.0323\n\nAggregated Metrics:\nMicro F1: 0.9153, Macro F1: 0.4940\nConfusion Matrix:\n[[   2   54]\n [  66 1294]]\nUpdated best_checkpoint.pt with Macro F1: 0.4940, False F1: 0.0323\n\n=== Epoch 3/15 Metrics ===\nTrain Loss: 0.0816\nValidation Loss: 0.0753\n\nPer-Class Metrics:\nTrue Precision: 0.9617, False Precision: 0.0602\nTrue Recall: 0.9426, False Recall: 0.0893\nTrue F1: 0.9521, False F1: 0.0719\n\nAggregated Metrics:\nMicro F1: 0.9089, Macro F1: 0.5120\nConfusion Matrix:\n[[   5   51]\n [  78 1282]]\nUpdated best_checkpoint.pt with Macro F1: 0.5120, False F1: 0.0719\n\n=== Epoch 4/15 Metrics ===\nTrain Loss: 0.0802\nValidation Loss: 0.0743\n\nPer-Class Metrics:\nTrue Precision: 0.9635, False Precision: 0.0792\nTrue Recall: 0.9316, False Recall: 0.1429\nTrue F1: 0.9473, False F1: 0.1019\n\nAggregated Metrics:\nMicro F1: 0.9004, Macro F1: 0.5246\nConfusion Matrix:\n[[   8   48]\n [  93 1267]]\nUpdated best_checkpoint.pt with Macro F1: 0.5246, False F1: 0.1019\n\n=== Epoch 5/15 Metrics ===\nTrain Loss: 0.0795\nValidation Loss: 0.0736\n\nPer-Class Metrics:\nTrue Precision: 0.9673, False Precision: 0.1069\nTrue Recall: 0.9140, False Recall: 0.2500\nTrue F1: 0.9399, False F1: 0.1497\n\nAggregated Metrics:\nMicro F1: 0.8877, Macro F1: 0.5448\nConfusion Matrix:\n[[  14   42]\n [ 117 1243]]\nUpdated best_checkpoint.pt with Macro F1: 0.5448, False F1: 0.1497\n\n=== Epoch 6/15 Metrics ===\nTrain Loss: 0.0787\nValidation Loss: 0.0731\n\nPer-Class Metrics:\nTrue Precision: 0.9631, False Precision: 0.0702\nTrue Recall: 0.9221, False Recall: 0.1429\nTrue F1: 0.9421, False F1: 0.0941\n\nAggregated Metrics:\nMicro F1: 0.8912, Macro F1: 0.5181\nConfusion Matrix:\n[[   8   48]\n [ 106 1254]]\n\n=== Epoch 7/15 Metrics ===\nTrain Loss: 0.0785\nValidation Loss: 0.0727\n\nPer-Class Metrics:\nTrue Precision: 0.9631, False Precision: 0.0702\nTrue Recall: 0.9221, False Recall: 0.1429\nTrue F1: 0.9421, False F1: 0.0941\n\nAggregated Metrics:\nMicro F1: 0.8912, Macro F1: 0.5181\nConfusion Matrix:\n[[   8   48]\n [ 106 1254]]\n\n=== Epoch 8/15 Metrics ===\nTrain Loss: 0.0776\nValidation Loss: 0.0725\n\nPer-Class Metrics:\nTrue Precision: 0.9631, False Precision: 0.0702\nTrue Recall: 0.9221, False Recall: 0.1429\nTrue F1: 0.9421, False F1: 0.0941\n\nAggregated Metrics:\nMicro F1: 0.8912, Macro F1: 0.5181\nConfusion Matrix:\n[[   8   48]\n [ 106 1254]]\n\n=== Epoch 11/15 Metrics ===\nTrain Loss: 0.0764\nValidation Loss: 0.0721\n\nPer-Class Metrics:\nTrue Precision: 0.9635, False Precision: 0.0792\nTrue Recall: 0.9316, False Recall: 0.1429\nTrue F1: 0.9473, False F1: 0.1019\n\nAggregated Metrics:\nMicro F1: 0.9004, Macro F1: 0.5246\nConfusion Matrix:\n[[   8   48]\n [  93 1267]]\n\n=== Epoch 12/15 Metrics ===\nTrain Loss: 0.0759\nValidation Loss: 0.0722\n\nPer-Class Metrics:\nTrue Precision: 0.9635, False Precision: 0.0792\nTrue Recall: 0.9316, False Recall: 0.1429\nTrue F1: 0.9473, False F1: 0.1019\n\nAggregated Metrics:\nMicro F1: 0.9004, Macro F1: 0.5246\nConfusion Matrix:\n[[   8   48]\n [  93 1267]]\n\n=== Epoch 13/15 Metrics ===\nTrain Loss: 0.0751\nValidation Loss: 0.0722\n\nPer-Class Metrics:\nTrue Precision: 0.9635, False Precision: 0.0792\nTrue Recall: 0.9316, False Recall: 0.1429\nTrue F1: 0.9473, False F1: 0.1019\n\nAggregated Metrics:\nMicro F1: 0.9004, Macro F1: 0.5246\nConfusion Matrix:\n[[   8   48]\n [  93 1267]]\n\n=== Epoch 14/15 Metrics ===\nTrain Loss: 0.0748\nValidation Loss: 0.0723\n\nPer-Class Metrics:\nTrue Precision: 0.9635, False Precision: 0.0792\nTrue Recall: 0.9316, False Recall: 0.1429\nTrue F1: 0.9473, False F1: 0.1019\n\nAggregated Metrics:\nMicro F1: 0.9004, Macro F1: 0.5246\nConfusion Matrix:\n[[   8   48]\n [  93 1267]]\n\n=== Epoch 15/15 Metrics ===\nTrain Loss: 0.0744\nValidation Loss: 0.0725\n\nPer-Class Metrics:\nTrue Precision: 0.9632, False Precision: 0.0814\nTrue Recall: 0.9419, False Recall: 0.1250\nTrue F1: 0.9524, False F1: 0.0986\n\nAggregated Metrics:\nMicro F1: 0.9096, Macro F1: 0.5255\nConfusion Matrix:\n[[   7   49]\n [  79 1281]]\n\n=== Final Test Metrics ===\nTest Loss: 0.1344\n\nPer-Class Metrics:\nTrue Precision: 0.9145, False Precision: 0.1152\nTrue Recall: 0.9324, False Recall: 0.0917\nTrue F1: 0.9234, False F1: 0.1021\n\nAggregated Metrics:\nMicro F1: 0.8588, Macro F1: 0.5127\nConfusion Matrix:\n[[  22  218]\n [ 169 2332]]\n\n=== Epoch 1/15 Metrics ===\nTrain Loss: 0.0843\nValidation Loss: 0.0767\n\nPer-Class Metrics:\nTrue Precision: 0.9606, False Precision: 0.0526\nTrue Recall: 0.9868, False Recall: 0.0179\nTrue F1: 0.9735, False F1: 0.0267\n\nAggregated Metrics:\nMicro F1: 0.9484, Macro F1: 0.5001\nConfusion Matrix:\n[[   1   55]\n [  18 1342]]\nUpdated best_checkpoint.pt with Macro F1: 0.5001, False F1: 0.0267\n\n=== Epoch 2/15 Metrics ===\nTrain Loss: 0.0838\nValidation Loss: 0.0744\n\nPer-Class Metrics:\nTrue Precision: 0.9623, False Precision: 0.1081\nTrue Recall: 0.9757, False Recall: 0.0714\nTrue F1: 0.9690, False F1: 0.0860\n\nAggregated Metrics:\nMicro F1: 0.9400, Macro F1: 0.5275\nConfusion Matrix:\n[[   4   52]\n [  33 1327]]\nUpdated best_checkpoint.pt with Macro F1: 0.5275, False F1: 0.0860\n\n=== Epoch 3/15 Metrics ===\nTrain Loss: 0.0822\nValidation Loss: 0.0730\n\nPer-Class Metrics:\nTrue Precision: 0.9638, False Precision: 0.0899\nTrue Recall: 0.9404, False Recall: 0.1429\nTrue F1: 0.9520, False F1: 0.1103\n\nAggregated Metrics:\nMicro F1: 0.9089, Macro F1: 0.5312\nConfusion Matrix:\n[[   8   48]\n [  81 1279]]\nUpdated best_checkpoint.pt with Macro F1: 0.5312, False F1: 0.1103\n\n=== Epoch 4/15 Metrics ===\nTrain Loss: 0.0804\nValidation Loss: 0.0723\n\nPer-Class Metrics:\nTrue Precision: 0.9638, False Precision: 0.0899\nTrue Recall: 0.9404, False Recall: 0.1429\nTrue F1: 0.9520, False F1: 0.1103\n\nAggregated Metrics:\nMicro F1: 0.9089, Macro F1: 0.5312\nConfusion Matrix:\n[[   8   48]\n [  81 1279]]\n\n=== Epoch 5/15 Metrics ===\nTrain Loss: 0.0800\nValidation Loss: 0.0722\n\nPer-Class Metrics:\nTrue Precision: 0.9638, False Precision: 0.0899\nTrue Recall: 0.9404, False Recall: 0.1429\nTrue F1: 0.9520, False F1: 0.1103\n\nAggregated Metrics:\nMicro F1: 0.9089, Macro F1: 0.5312\nConfusion Matrix:\n[[   8   48]\n [  81 1279]]\n\n=== Epoch 6/15 Metrics ===\nTrain Loss: 0.0787\nValidation Loss: 0.0722\n\nPer-Class Metrics:\nTrue Precision: 0.9638, False Precision: 0.0899\nTrue Recall: 0.9404, False Recall: 0.1429\nTrue F1: 0.9520, False F1: 0.1103\n\nAggregated Metrics:\nMicro F1: 0.9089, Macro F1: 0.5312\nConfusion Matrix:\n[[   8   48]\n [  81 1279]]\n\n=== Epoch 7/15 Metrics ===\nTrain Loss: 0.0777\nValidation Loss: 0.0724\n\nPer-Class Metrics:\nTrue Precision: 0.9638, False Precision: 0.0899\nTrue Recall: 0.9404, False Recall: 0.1429\nTrue F1: 0.9520, False F1: 0.1103\n\nAggregated Metrics:\nMicro F1: 0.9089, Macro F1: 0.5312\nConfusion Matrix:\n[[   8   48]\n [  81 1279]]\n\n=== Epoch 8/15 Metrics ===\nTrain Loss: 0.0772\nValidation Loss: 0.0728\n\nPer-Class Metrics:\nTrue Precision: 0.9638, False Precision: 0.0899\nTrue Recall: 0.9404, False Recall: 0.1429\nTrue F1: 0.9520, False F1: 0.1103\n\nAggregated Metrics:\nMicro F1: 0.9089, Macro F1: 0.5312\nConfusion Matrix:\n[[   8   48]\n [  81 1279]]\n\n=== Epoch 9/15 Metrics ===\nTrain Loss: 0.0759\nValidation Loss: 0.0730\n\nPer-Class Metrics:\nTrue Precision: 0.9638, False Precision: 0.0899\nTrue Recall: 0.9404, False Recall: 0.1429\nTrue F1: 0.9520, False F1: 0.1103\n\nAggregated Metrics:\nMicro F1: 0.9089, Macro F1: 0.5312\nConfusion Matrix:\n[[   8   48]\n [  81 1279]]\n\n=== Epoch 10/15 Metrics ===\nTrain Loss: 0.0755\nValidation Loss: 0.0736\n\nPer-Class Metrics:\nTrue Precision: 0.9638, False Precision: 0.0899\nTrue Recall: 0.9404, False Recall: 0.1429\nTrue F1: 0.9520, False F1: 0.1103\n\nAggregated Metrics:\nMicro F1: 0.9089, Macro F1: 0.5312\nConfusion Matrix:\n[[   8   48]\n [  81 1279]]\n\n=== Epoch 11/15 Metrics ===\nTrain Loss: 0.0749\nValidation Loss: 0.0735\n\nPer-Class Metrics:\nTrue Precision: 0.9638, False Precision: 0.0899\nTrue Recall: 0.9404, False Recall: 0.1429\nTrue F1: 0.9520, False F1: 0.1103\n\nAggregated Metrics:\nMicro F1: 0.9089, Macro F1: 0.5312\nConfusion Matrix:\n[[   8   48]\n [  81 1279]]\n\n=== Epoch 12/15 Metrics ===\nTrain Loss: 0.0741\nValidation Loss: 0.0742\n\nPer-Class Metrics:\nTrue Precision: 0.9638, False Precision: 0.0899\nTrue Recall: 0.9404, False Recall: 0.1429\nTrue F1: 0.9520, False F1: 0.1103\n\nAggregated Metrics:\nMicro F1: 0.9089, Macro F1: 0.5312\nConfusion Matrix:\n[[   8   48]\n [  81 1279]]\n\n=== Epoch 13/15 Metrics ===\nTrain Loss: 0.0739\nValidation Loss: 0.0742\n\nPer-Class Metrics:\nTrue Precision: 0.9638, False Precision: 0.0899\nTrue Recall: 0.9404, False Recall: 0.1429\nTrue F1: 0.9520, False F1: 0.1103\n\nAggregated Metrics:\nMicro F1: 0.9089, Macro F1: 0.5312\nConfusion Matrix:\n[[   8   48]\n [  81 1279]]\n\n=== Epoch 14/15 Metrics ===\nTrain Loss: 0.0732\nValidation Loss: 0.0749\n\nPer-Class Metrics:\nTrue Precision: 0.9633, False Precision: 0.0734\nTrue Recall: 0.9257, False Recall: 0.1429\nTrue F1: 0.9441, False F1: 0.0970\n\nAggregated Metrics:\nMicro F1: 0.8948, Macro F1: 0.5206\nConfusion Matrix:\n[[   8   48]\n [ 101 1259]]\n\n=== Epoch 15/15 Metrics ===\nTrain Loss: 0.0728\nValidation Loss: 0.0748\n\nPer-Class Metrics:\nTrue Precision: 0.9641, False Precision: 0.1346\nTrue Recall: 0.9669, False Recall: 0.1250\nTrue F1: 0.9655, False F1: 0.1296\n\nAggregated Metrics:\nMicro F1: 0.9336, Macro F1: 0.5476\nConfusion Matrix:\n[[   7   49]\n [  45 1315]]\nUpdated best_checkpoint.pt with Macro F1: 0.5476, False F1: 0.1296\n\n=== Final Test Metrics ===\nTest Loss: 0.1433\n\nPer-Class Metrics:\nTrue Precision: 0.9197, False Precision: 0.1026\nTrue Recall: 0.6781, False Recall: 0.3833\nTrue F1: 0.7807, False F1: 0.1618\n\nAggregated Metrics:\nMicro F1: 0.6523, Macro F1: 0.4712\nConfusion Matrix:\n[[  92  148]\n [ 805 1696]]\n\n=== Epoch 1/15 Metrics ===\nTrain Loss: 0.1011\nValidation Loss: 0.0793\n\nPer-Class Metrics:\nTrue Precision: 0.9595, False Precision: 0.0000\nTrue Recall: 0.9750, False Recall: 0.0000\nTrue F1: 0.9672, False F1: 0.0000\n\nAggregated Metrics:\nMicro F1: 0.9364, Macro F1: 0.4836\nConfusion Matrix:\n[[   0   56]\n [  34 1326]]\nUpdated best_checkpoint.pt with Macro F1: 0.4836, False F1: 0.0000\n\n=== Epoch 2/15 Metrics ===\nTrain Loss: 0.0818\nValidation Loss: 0.0765\n\nPer-Class Metrics:\nTrue Precision: 0.9601, False Precision: 0.0000\nTrue Recall: 0.9912, False Recall: 0.0000\nTrue F1: 0.9754, False F1: 0.0000\n\nAggregated Metrics:\nMicro F1: 0.9520, Macro F1: 0.4877\nConfusion Matrix:\n[[   0   56]\n [  12 1348]]\nUpdated best_checkpoint.pt with Macro F1: 0.4877, False F1: 0.0000\n\n=== Epoch 3/15 Metrics ===\nTrain Loss: 0.0801\nValidation Loss: 0.0751\n\nPer-Class Metrics:\nTrue Precision: 0.9618, False Precision: 0.1000\nTrue Recall: 0.9801, False Recall: 0.0536\nTrue F1: 0.9709, False F1: 0.0698\n\nAggregated Metrics:\nMicro F1: 0.9435, Macro F1: 0.5203\nConfusion Matrix:\n[[   3   53]\n [  27 1333]]\nUpdated best_checkpoint.pt with Macro F1: 0.5203, False F1: 0.0698\n\n=== Epoch 4/15 Metrics ===\nTrain Loss: 0.0793\nValidation Loss: 0.0742\n\nPer-Class Metrics:\nTrue Precision: 0.9630, False Precision: 0.0923\nTrue Recall: 0.9566, False Recall: 0.1071\nTrue F1: 0.9598, False F1: 0.0992\n\nAggregated Metrics:\nMicro F1: 0.9230, Macro F1: 0.5295\nConfusion Matrix:\n[[   6   50]\n [  59 1301]]\nUpdated best_checkpoint.pt with Macro F1: 0.5295, False F1: 0.0992\n\n=== Epoch 5/15 Metrics ===\nTrain Loss: 0.0785\nValidation Loss: 0.0736\n\nPer-Class Metrics:\nTrue Precision: 0.9640, False Precision: 0.1273\nTrue Recall: 0.9647, False Recall: 0.1250\nTrue F1: 0.9644, False F1: 0.1261\n\nAggregated Metrics:\nMicro F1: 0.9315, Macro F1: 0.5452\nConfusion Matrix:\n[[   7   49]\n [  48 1312]]\nUpdated best_checkpoint.pt with Macro F1: 0.5452, False F1: 0.1261\n\n=== Epoch 6/15 Metrics ===\nTrain Loss: 0.0781\nValidation Loss: 0.0734\n\nPer-Class Metrics:\nTrue Precision: 0.9643, False Precision: 0.1628\nTrue Recall: 0.9735, False Recall: 0.1250\nTrue F1: 0.9689, False F1: 0.1414\n\nAggregated Metrics:\nMicro F1: 0.9400, Macro F1: 0.5552\nConfusion Matrix:\n[[   7   49]\n [  36 1324]]\nSaved checkpoint checkpoint_epoch_6_macroF1_0.5552_falseF1_0.1414.pt (False F1: 0.1414, Macro F1: 0.5552)\nUpdated best_checkpoint.pt with Macro F1: 0.5552, False F1: 0.1414\n\n=== Epoch 7/15 Metrics ===\nTrain Loss: 0.0773\nValidation Loss: 0.0732\n\nPer-Class Metrics:\nTrue Precision: 0.9641, False Precision: 0.1346\nTrue Recall: 0.9669, False Recall: 0.1250\nTrue F1: 0.9655, False F1: 0.1296\n\nAggregated Metrics:\nMicro F1: 0.9336, Macro F1: 0.5476\nConfusion Matrix:\n[[   7   49]\n [  45 1315]]\n\n=== Epoch 8/15 Metrics ===\nTrain Loss: 0.0768\nValidation Loss: 0.0730\n\nPer-Class Metrics:\nTrue Precision: 0.9641, False Precision: 0.1346\nTrue Recall: 0.9669, False Recall: 0.1250\nTrue F1: 0.9655, False F1: 0.1296\n\nAggregated Metrics:\nMicro F1: 0.9336, Macro F1: 0.5476\nConfusion Matrix:\n[[   7   49]\n [  45 1315]]\n\n=== Epoch 9/15 Metrics ===\nTrain Loss: 0.0763\nValidation Loss: 0.0730\n\nPer-Class Metrics:\nTrue Precision: 0.9641, False Precision: 0.1346\nTrue Recall: 0.9669, False Recall: 0.1250\nTrue F1: 0.9655, False F1: 0.1296\n\nAggregated Metrics:\nMicro F1: 0.9336, Macro F1: 0.5476\nConfusion Matrix:\n[[   7   49]\n [  45 1315]]\n\n=== Epoch 10/15 Metrics ===\nTrain Loss: 0.0759\nValidation Loss: 0.0730\n\nPer-Class Metrics:\nTrue Precision: 0.9641, False Precision: 0.1346\nTrue Recall: 0.9669, False Recall: 0.1250\nTrue F1: 0.9655, False F1: 0.1296\n\nAggregated Metrics:\nMicro F1: 0.9336, Macro F1: 0.5476\nConfusion Matrix:\n[[   7   49]\n [  45 1315]]\n\n=== Epoch 11/15 Metrics ===\nTrain Loss: 0.0754\nValidation Loss: 0.0729\n\nPer-Class Metrics:\nTrue Precision: 0.9641, False Precision: 0.1346\nTrue Recall: 0.9669, False Recall: 0.1250\nTrue F1: 0.9655, False F1: 0.1296\n\nAggregated Metrics:\nMicro F1: 0.9336, Macro F1: 0.5476\nConfusion Matrix:\n[[   7   49]\n [  45 1315]]\n\n=== Epoch 12/15 Metrics ===\nTrain Loss: 0.0749\nValidation Loss: 0.0732\n\nPer-Class Metrics:\nTrue Precision: 0.9641, False Precision: 0.1346\nTrue Recall: 0.9669, False Recall: 0.1250\nTrue F1: 0.9655, False F1: 0.1296\n\nAggregated Metrics:\nMicro F1: 0.9336, Macro F1: 0.5476\nConfusion Matrix:\n[[   7   49]\n [  45 1315]]\n\n=== Epoch 13/15 Metrics ===\nTrain Loss: 0.0742\nValidation Loss: 0.0730\n\nPer-Class Metrics:\nTrue Precision: 0.9635, False Precision: 0.0946\nTrue Recall: 0.9507, False Recall: 0.1250\nTrue F1: 0.9571, False F1: 0.1077\n\nAggregated Metrics:\nMicro F1: 0.9181, Macro F1: 0.5324\nConfusion Matrix:\n[[   7   49]\n [  67 1293]]\n\n=== Epoch 14/15 Metrics ===\nTrain Loss: 0.0737\nValidation Loss: 0.0734\n\nPer-Class Metrics:\nTrue Precision: 0.9635, False Precision: 0.0946\nTrue Recall: 0.9507, False Recall: 0.1250\nTrue F1: 0.9571, False F1: 0.1077\n\nAggregated Metrics:\nMicro F1: 0.9181, Macro F1: 0.5324\nConfusion Matrix:\n[[   7   49]\n [  67 1293]]\n\n=== Epoch 15/15 Metrics ===\nTrain Loss: 0.0732\nValidation Loss: 0.0736\n\nPer-Class Metrics:\nTrue Precision: 0.9635, False Precision: 0.0946\nTrue Recall: 0.9507, False Recall: 0.1250\nTrue F1: 0.9571, False F1: 0.1077\n\nAggregated Metrics:\nMicro F1: 0.9181, Macro F1: 0.5324\nConfusion Matrix:\n[[   7   49]\n [  67 1293]]\n\n=== Final Test Metrics ===\nTest Loss: 0.1382\n\nPer-Class Metrics:\nTrue Precision: 0.9131, False Precision: 0.0920\nTrue Recall: 0.8776, False Recall: 0.1292\nTrue F1: 0.8950, False F1: 0.1075\n\nAggregated Metrics:\nMicro F1: 0.8121, Macro F1: 0.5012\nConfusion Matrix:\n[[  31  209]\n [ 306 2195]]\n\n=== Per-Class Metrics (for 'True' and 'False' classes) ===\nPrecision\nTrue_precision: 0.9181\nFalse_precision: 0.1157\nRecall\nTrue_recall: 0.8381\nFalse_recall: 0.2208\nF1-Score\nTrue_fscore: 0.8763\nFalse_fscore: 0.1519\n\n📊 Micro-Averaged Metrics\nmicro_precision: 0.7840\nmicro_recall: 0.7840\nmicro_fscore: 0.7840\n\n📈 Macro-Averaged Metrics\nmacro_precision: 0.5169\nmacro_recall: 0.5294\nmacro_fscore: 0.5141\n\n🧠 Loss\ntraining_loss: 0.0771\nvalidation_loss: 0.0722\nbest_validation_loss: 0.0734\ntest_loss: 0.1252\n\n🧪 Best Validation Metrics\nbest_validation_True_precision: 0.9680\nbest_validation_False_precision: 0.1781\nbest_validation_True_recall: 0.9559\nbest_validation_False_recall: 0.2321\nbest_validation_True_fscore: 0.9619\nbest_validation_False_fscore: 0.2016\nbest_validation_micro_precision: 0.9273\nbest_validation_micro_recall: 0.9273\nbest_validation_micro_fscore: 0.9273\nbest_validation_macro_precision: 0.5730\nbest_validation_macro_recall: 0.5940\nbest_validation_macro_fscore: 0.5817\n\n🔍 Test Confusion Matrix\n[[  53  187]\n [ 405 2096]]\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"import os\nprint(os.listdir('checkpoints'))","metadata":{"trusted":true},"outputs":[{"name":"stdout","text":"['checkpoint_epoch_3_macroF1_0.5734_falseF1_0.1884.pt', 'checkpoint_epoch_13.pt', 'checkpoint_epoch_9_macroF1_0.5734_falseF1_0.1884.pt', 'checkpoint_epoch_12.pt', 'checkpoint_epoch_3_macroF1_0.5739_falseF1_0.1782.pt', 'checkpoint_epoch_7_macroF1_0.5734_falseF1_0.1884.pt', 'checkpoint_epoch_2_macroF1_0.5817_falseF1_0.2016.pt', 'checkpoint_epoch_14_macroF1_0.5504_falseF1_0.1573.pt', 'checkpoint_epoch_6.pt', 'model_lr5e-05_bs4.pth', 'checkpoint_epoch_6_macroF1_0.5817_falseF1_0.2016.pt', 'checkpoint_epoch_4_macroF1_0.5739_falseF1_0.1782.pt', 'checkpoint_epoch_5_macroF1_0.5734_falseF1_0.1884.pt', 'checkpoint_epoch_5_macroF1_0.5739_falseF1_0.1782.pt', 'checkpoint_epoch_5_macroF1_0.5558_falseF1_0.1527.pt', 'checkpoint_epoch_13_macroF1_0.5564_falseF1_0.1657.pt', 'checkpoint_epoch_4_macroF1_0.5558_falseF1_0.1527.pt', 'checkpoint_epoch_2.pt', 'model_lr0.0001_bs4.pth', 'model_lr0.0002_bs8.pth', 'checkpoint_epoch_8.pt', 'model_lr5e-05_bs8.pth', 'model_lr0.0001_bs8.pth', 'checkpoint_epoch_15.pt', 'checkpoint_epoch_1.pt', 'checkpoint_epoch_6_macroF1_0.5552_falseF1_0.1414.pt', 'checkpoint_epoch_11.pt', 'checkpoint_epoch_12_macroF1_0.5564_falseF1_0.1657.pt', 'checkpoint_epoch_5.pt', 'checkpoint_epoch_14.pt', 'checkpoint_epoch_15_macroF1_0.5504_falseF1_0.1573.pt', 'checkpoint_epoch_10.pt', 'checkpoint_epoch_9.pt', 'checkpoint_epoch_8_macroF1_0.5734_falseF1_0.1884.pt', 'checkpoint_epoch_7.pt', 'checkpoint_epoch_6_macroF1_0.5734_falseF1_0.1884.pt', 'checkpoint_epoch_10_macroF1_0.5734_falseF1_0.1884.pt', 'checkpoint_epoch_3.pt', 'checkpoint_epoch_7_macroF1_0.5817_falseF1_0.2016.pt', 'checkpoint_epoch_4_macroF1_0.5734_falseF1_0.1884.pt', 'best_checkpoint.pt', 'model_lr0.0002_bs4.pth', 'checkpoint_epoch_11_macroF1_0.5564_falseF1_0.1657.pt', 'checkpoint_epoch_4.pt']\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"import os\nimport zipfile\n\n# Define the directory containing checkpoints\ncheckpoint_dir = 'checkpoints'\n\n# Define the output zip file name\nzip_file_name = 'checkpoints_backup.zip'\n\n# Create a zip file\nwith zipfile.ZipFile(zip_file_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n    for file_name in os.listdir(checkpoint_dir):\n        file_path = os.path.join(checkpoint_dir, file_name)\n        if os.path.isfile(file_path):  # Ensure it's a file\n            zipf.write(file_path, os.path.relpath(file_path, os.path.dirname(checkpoint_dir)))\n\nprint(f\"Created {zip_file_name} with all checkpoint files.\")","metadata":{"trusted":true},"outputs":[{"name":"stdout","text":"Created checkpoints_backup.zip with all checkpoint files.\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"import os\nprint(os.listdir('/kaggle/working/'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T08:09:35.496396Z","iopub.execute_input":"2025-04-15T08:09:35.496684Z","iopub.status.idle":"2025-04-15T08:09:35.501239Z","shell.execute_reply.started":"2025-04-15T08:09:35.496657Z","shell.execute_reply":"2025-04-15T08:09:35.500404Z"}},"outputs":[{"name":"stdout","text":"['checkpoints', 'checkpoints_backup.zip', '.ipynb_checkpoints', '.virtual_documents']\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.nn.utils.rnn import pad_sequence\nimport numpy as np\nimport glob\n\n# Get a list of all checkpoint files in the 'checkpoints' directory\ncheckpoint_files = glob.glob('checkpoints/*.pt')\n\ndef evaluate_model(model, checkpoint_path, data, batch_size=4):\n    \"\"\"\n    Load a checkpoint and evaluate the model on the provided data, ensuring metrics match those saved.\n    \n    Args:\n        model (EnhancedDeceptionDetector): The model instance to evaluate.\n        checkpoint_path (str): Path to the saved checkpoint file.\n        data (list): Preprocessed data (e.g., val_data) to evaluate on.\n        batch_size (int): Batch size for evaluation.\n    \"\"\"\n    # Load the checkpoint\n    checkpoint = torch.load(checkpoint_path, map_location=device)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    model.to(device)\n    model.eval()\n\n    # Define the loss function with the checkpoint's pos_weight\n    pos_weight = checkpoint['pos_weight']\n    criterion = nn.BCEWithLogitsLoss(\n        pos_weight=torch.tensor([pos_weight], device=device), reduction='none'\n    )\n\n    # Evaluation loop\n    total_loss = 0\n    all_preds, all_labels = [], []\n    with torch.no_grad():\n        for i in range(0, len(data), batch_size):\n            batch = data[i:i + batch_size]\n            messages = [c['messages'] for c in batch]\n            ling_features = [c['ling_features'] for c in batch]\n            senders = pad_sequence(\n                [c['speakers'] for c in batch], batch_first=True, \n                padding_value=model.country_embedding.padding_idx\n            ).to(device)\n            receivers = pad_sequence(\n                [c['receivers'] for c in batch], batch_first=True, \n                padding_value=model.country_embedding.padding_idx\n            ).to(device)\n            seasons = pad_sequence(\n                [c['seasons'] for c in batch], batch_first=True, \n                padding_value=model.season_embedding.padding_idx\n            ).to(device)\n            years = pad_sequence(\n                [c['years'] for c in batch], batch_first=True, \n                padding_value=model.year_embedding.padding_idx\n            ).to(device)\n            game_scores = pad_sequence(\n                [c['game_scores'] for c in batch], batch_first=True, padding_value=0\n            ).to(device)\n            game_score_deltas = pad_sequence(\n                [c['game_score_deltas'] for c in batch], batch_first=True, padding_value=0\n            ).to(device)\n            sender_labels = pad_sequence(\n                [c['sender_labels'] for c in batch], batch_first=True, padding_value=-1\n            ).to(device)\n            lengths = [len(c['messages']) for c in batch]\n\n            # Forward pass\n            final_pred = model(\n                messages, ling_features, senders, receivers, seasons, years,\n                game_scores, game_score_deltas, lengths\n            )\n            loss = criterion(final_pred.squeeze(-1), sender_labels)\n            mask = (sender_labels != -1)\n            loss = (loss * mask).sum() / (mask.sum() + 1e-8)\n            total_loss += loss.item()\n\n            all_preds.append(final_pred.squeeze(-1)[mask])\n            all_labels.append(sender_labels[mask])\n\n    # Compute average loss and metrics\n    avg_loss = total_loss / (len(data) / batch_size)\n    all_preds = torch.cat(all_preds)\n    all_labels = torch.cat(all_labels)\n    metrics = compute_metrics(all_preds, all_labels)\n\n    # Print results\n    print(f\"Loaded checkpoint from epoch {checkpoint['epoch']}\")\n    print(f\"Stored validation loss: {checkpoint['val_loss']:.4f}\")\n    print(f\"Computed validation loss: {avg_loss:.4f}\")\n    print(f\"Stored metrics: {checkpoint['metrics']}\")\n    print(f\"Computed metrics: {metrics}\")\n\n    # Optional verification (can be removed if strict equality isn't required)\n    # assert np.isclose(avg_loss, checkpoint['val_loss'], rtol=1e-5), \"Validation loss mismatch\"\n    for key in metrics:\n        if key != 'confusion_matrix':  # Confusion matrix is a numpy array\n            assert np.isclose(metrics[key], checkpoint['metrics'][key], rtol=1e-5), f\"Mismatch in {key}\"\n        else:\n            assert np.array_equal(metrics[key], checkpoint['metrics'][key]), \"Confusion matrix mismatch\"\n\nfor checkpoint_file in checkpoint_files:\n    print(f\"\\nEvaluating checkpoint: {checkpoint_file}\")\n    evaluate_model(model, checkpoint_file, val_data, batch_size=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T09:42:45.347111Z","iopub.execute_input":"2025-04-15T09:42:45.347844Z","iopub.status.idle":"2025-04-15T09:42:54.632048Z","shell.execute_reply.started":"2025-04-15T09:42:45.347818Z","shell.execute_reply":"2025-04-15T09:42:54.631228Z"}},"outputs":[{"name":"stdout","text":"\nEvaluating checkpoint: checkpoints/checkpoint_epoch_3_macroF1_0.5734_falseF1_0.1884.pt\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/118544494.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(checkpoint_path, map_location=device)\n","output_type":"stream"},{"name":"stdout","text":"Loaded checkpoint from epoch 3\nStored validation loss: 0.0734\nComputed validation loss: 0.0734\nStored metrics: {'True_precision': 0.9677661169415293, 'False_precision': 0.15853658536585366, 'True_recall': 0.9492647058823529, 'False_recall': 0.23214285714285715, 'True_fscore': 0.9584261321455085, 'False_fscore': 0.1884057971014493, 'micro_precision': 0.9209039548022598, 'micro_recall': 0.9209039548022598, 'micro_fscore': 0.9209039548022597, 'macro_precision': 0.5631513511536914, 'macro_recall': 0.590703781512605, 'macro_fscore': 0.5734159646234789, 'confusion_matrix': array([[  13,   43],\n       [  69, 1291]])}\nComputed metrics: {'True_precision': 0.9677661169415293, 'False_precision': 0.15853658536585366, 'True_recall': 0.9492647058823529, 'False_recall': 0.23214285714285715, 'True_fscore': 0.9584261321455085, 'False_fscore': 0.1884057971014493, 'micro_precision': 0.9209039548022598, 'micro_recall': 0.9209039548022598, 'micro_fscore': 0.9209039548022597, 'macro_precision': 0.5631513511536914, 'macro_recall': 0.590703781512605, 'macro_fscore': 0.5734159646234789, 'confusion_matrix': array([[  13,   43],\n       [  69, 1291]])}\n\nEvaluating checkpoint: checkpoints/checkpoint_epoch_13.pt\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/118544494.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(checkpoint_path, map_location=device)\n","output_type":"stream"},{"name":"stdout","text":"Loaded checkpoint from epoch 13\nStored validation loss: 0.0945\nComputed validation loss: 0.0729\nStored metrics: {'True_precision': 0.9634873323397913, 'False_precision': 0.0945945945945946, 'True_recall': 0.950735294117647, 'False_recall': 0.125, 'True_fscore': 0.9570688378978534, 'False_fscore': 0.1076923076923077, 'micro_precision': 0.9180790960451978, 'micro_recall': 0.9180790960451978, 'micro_fscore': 0.9180790960451978, 'macro_precision': 0.529040963467193, 'macro_recall': 0.5378676470588235, 'macro_fscore': 0.5323805727950806, 'confusion_matrix': array([[   7,   49],\n       [  67, 1293]])}\nComputed metrics: {'True_precision': 0.9634873323397913, 'False_precision': 0.0945945945945946, 'True_recall': 0.950735294117647, 'False_recall': 0.125, 'True_fscore': 0.9570688378978534, 'False_fscore': 0.1076923076923077, 'micro_precision': 0.9180790960451978, 'micro_recall': 0.9180790960451978, 'micro_fscore': 0.9180790960451978, 'macro_precision': 0.529040963467193, 'macro_recall': 0.5378676470588235, 'macro_fscore': 0.5323805727950806, 'confusion_matrix': array([[   7,   49],\n       [  67, 1293]])}\n\nEvaluating checkpoint: checkpoints/checkpoint_epoch_9_macroF1_0.5734_falseF1_0.1884.pt\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/118544494.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(checkpoint_path, map_location=device)\n","output_type":"stream"},{"name":"stdout","text":"Loaded checkpoint from epoch 9\nStored validation loss: 0.0727\nComputed validation loss: 0.0727\nStored metrics: {'True_precision': 0.9677661169415293, 'False_precision': 0.15853658536585366, 'True_recall': 0.9492647058823529, 'False_recall': 0.23214285714285715, 'True_fscore': 0.9584261321455085, 'False_fscore': 0.1884057971014493, 'micro_precision': 0.9209039548022598, 'micro_recall': 0.9209039548022598, 'micro_fscore': 0.9209039548022597, 'macro_precision': 0.5631513511536914, 'macro_recall': 0.590703781512605, 'macro_fscore': 0.5734159646234789, 'confusion_matrix': array([[  13,   43],\n       [  69, 1291]])}\nComputed metrics: {'True_precision': 0.9677661169415293, 'False_precision': 0.15853658536585366, 'True_recall': 0.9492647058823529, 'False_recall': 0.23214285714285715, 'True_fscore': 0.9584261321455085, 'False_fscore': 0.1884057971014493, 'micro_precision': 0.9209039548022598, 'micro_recall': 0.9209039548022598, 'micro_fscore': 0.9209039548022597, 'macro_precision': 0.5631513511536914, 'macro_recall': 0.590703781512605, 'macro_fscore': 0.5734159646234789, 'confusion_matrix': array([[  13,   43],\n       [  69, 1291]])}\n\nEvaluating checkpoint: checkpoints/checkpoint_epoch_12.pt\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/118544494.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(checkpoint_path, map_location=device)\n","output_type":"stream"},{"name":"stdout","text":"Loaded checkpoint from epoch 12\nStored validation loss: 0.0947\nComputed validation loss: 0.0730\nStored metrics: {'True_precision': 0.9640762463343109, 'False_precision': 0.1346153846153846, 'True_recall': 0.9669117647058824, 'False_recall': 0.125, 'True_fscore': 0.9654919236417033, 'False_fscore': 0.12962962962962965, 'micro_precision': 0.9336158192090396, 'micro_recall': 0.9336158192090396, 'micro_fscore': 0.9336158192090396, 'macro_precision': 0.5493458154748477, 'macro_recall': 0.5459558823529411, 'macro_fscore': 0.5475607766356665, 'confusion_matrix': array([[   7,   49],\n       [  45, 1315]])}\nComputed metrics: {'True_precision': 0.9640762463343109, 'False_precision': 0.1346153846153846, 'True_recall': 0.9669117647058824, 'False_recall': 0.125, 'True_fscore': 0.9654919236417033, 'False_fscore': 0.12962962962962965, 'micro_precision': 0.9336158192090396, 'micro_recall': 0.9336158192090396, 'micro_fscore': 0.9336158192090396, 'macro_precision': 0.5493458154748477, 'macro_recall': 0.5459558823529411, 'macro_fscore': 0.5475607766356665, 'confusion_matrix': array([[   7,   49],\n       [  45, 1315]])}\n\nEvaluating checkpoint: checkpoints/checkpoint_epoch_3_macroF1_0.5739_falseF1_0.1782.pt\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/118544494.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(checkpoint_path, map_location=device)\n","output_type":"stream"},{"name":"stdout","text":"Loaded checkpoint from epoch 3\nStored validation loss: 0.0758\nComputed validation loss: 0.0758\nStored metrics: {'True_precision': 0.9657184536834428, 'False_precision': 0.2, 'True_recall': 0.9735294117647059, 'False_recall': 0.16071428571428573, 'True_fscore': 0.9696082021237642, 'False_fscore': 0.1782178217821782, 'micro_precision': 0.9413841807909604, 'micro_recall': 0.9413841807909604, 'micro_fscore': 0.9413841807909604, 'macro_precision': 0.5828592268417214, 'macro_recall': 0.5671218487394958, 'macro_fscore': 0.5739130119529712, 'confusion_matrix': array([[   9,   47],\n       [  36, 1324]])}\nComputed metrics: {'True_precision': 0.9657184536834428, 'False_precision': 0.2, 'True_recall': 0.9735294117647059, 'False_recall': 0.16071428571428573, 'True_fscore': 0.9696082021237642, 'False_fscore': 0.1782178217821782, 'micro_precision': 0.9413841807909604, 'micro_recall': 0.9413841807909604, 'micro_fscore': 0.9413841807909604, 'macro_precision': 0.5828592268417214, 'macro_recall': 0.5671218487394958, 'macro_fscore': 0.5739130119529712, 'confusion_matrix': array([[   9,   47],\n       [  36, 1324]])}\n\nEvaluating checkpoint: checkpoints/checkpoint_epoch_7_macroF1_0.5734_falseF1_0.1884.pt\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/118544494.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(checkpoint_path, map_location=device)\n","output_type":"stream"},{"name":"stdout","text":"Loaded checkpoint from epoch 7\nStored validation loss: 0.0722\nComputed validation loss: 0.0722\nStored metrics: {'True_precision': 0.9677661169415293, 'False_precision': 0.15853658536585366, 'True_recall': 0.9492647058823529, 'False_recall': 0.23214285714285715, 'True_fscore': 0.9584261321455085, 'False_fscore': 0.1884057971014493, 'micro_precision': 0.9209039548022598, 'micro_recall': 0.9209039548022598, 'micro_fscore': 0.9209039548022597, 'macro_precision': 0.5631513511536914, 'macro_recall': 0.590703781512605, 'macro_fscore': 0.5734159646234789, 'confusion_matrix': array([[  13,   43],\n       [  69, 1291]])}\nComputed metrics: {'True_precision': 0.9677661169415293, 'False_precision': 0.15853658536585366, 'True_recall': 0.9492647058823529, 'False_recall': 0.23214285714285715, 'True_fscore': 0.9584261321455085, 'False_fscore': 0.1884057971014493, 'micro_precision': 0.9209039548022598, 'micro_recall': 0.9209039548022598, 'micro_fscore': 0.9209039548022597, 'macro_precision': 0.5631513511536914, 'macro_recall': 0.590703781512605, 'macro_fscore': 0.5734159646234789, 'confusion_matrix': array([[  13,   43],\n       [  69, 1291]])}\n\nEvaluating checkpoint: checkpoints/checkpoint_epoch_2_macroF1_0.5817_falseF1_0.2016.pt\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/118544494.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(checkpoint_path, map_location=device)\n","output_type":"stream"},{"name":"stdout","text":"Loaded checkpoint from epoch 2\nStored validation loss: 0.0747\nComputed validation loss: 0.0747\nStored metrics: {'True_precision': 0.9679821295606851, 'False_precision': 0.1780821917808219, 'True_recall': 0.9558823529411765, 'False_recall': 0.23214285714285715, 'True_fscore': 0.9618941916389198, 'False_fscore': 0.20155038759689922, 'micro_precision': 0.9272598870056498, 'micro_recall': 0.9272598870056498, 'micro_fscore': 0.9272598870056498, 'macro_precision': 0.5730321606707535, 'macro_recall': 0.5940126050420168, 'macro_fscore': 0.5817222896179095, 'confusion_matrix': array([[  13,   43],\n       [  60, 1300]])}\nComputed metrics: {'True_precision': 0.9679821295606851, 'False_precision': 0.1780821917808219, 'True_recall': 0.9558823529411765, 'False_recall': 0.23214285714285715, 'True_fscore': 0.9618941916389198, 'False_fscore': 0.20155038759689922, 'micro_precision': 0.9272598870056498, 'micro_recall': 0.9272598870056498, 'micro_fscore': 0.9272598870056498, 'macro_precision': 0.5730321606707535, 'macro_recall': 0.5940126050420168, 'macro_fscore': 0.5817222896179095, 'confusion_matrix': array([[  13,   43],\n       [  60, 1300]])}\n\nEvaluating checkpoint: checkpoints/checkpoint_epoch_14_macroF1_0.5504_falseF1_0.1573.pt\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/118544494.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(checkpoint_path, map_location=device)\n","output_type":"stream"},{"name":"stdout","text":"Loaded checkpoint from epoch 14\nStored validation loss: 0.0738\nComputed validation loss: 0.0738\nStored metrics: {'True_precision': 0.9675425038639877, 'False_precision': 0.11475409836065574, 'True_recall': 0.9205882352941176, 'False_recall': 0.25, 'True_fscore': 0.9434815373021853, 'False_fscore': 0.15730337078651685, 'micro_precision': 0.8940677966101694, 'micro_recall': 0.8940677966101694, 'micro_fscore': 0.8940677966101694, 'macro_precision': 0.5411483011123217, 'macro_recall': 0.5852941176470587, 'macro_fscore': 0.5503924540443511, 'confusion_matrix': array([[  14,   42],\n       [ 108, 1252]])}\nComputed metrics: {'True_precision': 0.9675425038639877, 'False_precision': 0.11475409836065574, 'True_recall': 0.9205882352941176, 'False_recall': 0.25, 'True_fscore': 0.9434815373021853, 'False_fscore': 0.15730337078651685, 'micro_precision': 0.8940677966101694, 'micro_recall': 0.8940677966101694, 'micro_fscore': 0.8940677966101694, 'macro_precision': 0.5411483011123217, 'macro_recall': 0.5852941176470587, 'macro_fscore': 0.5503924540443511, 'confusion_matrix': array([[  14,   42],\n       [ 108, 1252]])}\n\nEvaluating checkpoint: checkpoints/checkpoint_epoch_6.pt\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/118544494.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(checkpoint_path, map_location=device)\n","output_type":"stream"},{"name":"stdout","text":"Loaded checkpoint from epoch 6\nStored validation loss: 0.0734\nComputed validation loss: 0.0734\nStored metrics: {'True_precision': 0.9679821295606851, 'False_precision': 0.1780821917808219, 'True_recall': 0.9558823529411765, 'False_recall': 0.23214285714285715, 'True_fscore': 0.9618941916389198, 'False_fscore': 0.20155038759689922, 'micro_precision': 0.9272598870056498, 'micro_recall': 0.9272598870056498, 'micro_fscore': 0.9272598870056498, 'macro_precision': 0.5730321606707535, 'macro_recall': 0.5940126050420168, 'macro_fscore': 0.5817222896179095, 'confusion_matrix': array([[  13,   43],\n       [  60, 1300]])}\nComputed metrics: {'True_precision': 0.9679821295606851, 'False_precision': 0.1780821917808219, 'True_recall': 0.9558823529411765, 'False_recall': 0.23214285714285715, 'True_fscore': 0.9618941916389198, 'False_fscore': 0.20155038759689922, 'micro_precision': 0.9272598870056498, 'micro_recall': 0.9272598870056498, 'micro_fscore': 0.9272598870056498, 'macro_precision': 0.5730321606707535, 'macro_recall': 0.5940126050420168, 'macro_fscore': 0.5817222896179095, 'confusion_matrix': array([[  13,   43],\n       [  60, 1300]])}\n\nEvaluating checkpoint: checkpoints/checkpoint_epoch_6_macroF1_0.5817_falseF1_0.2016.pt\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/118544494.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(checkpoint_path, map_location=device)\n","output_type":"stream"},{"name":"stdout","text":"Loaded checkpoint from epoch 6\nStored validation loss: 0.0734\nComputed validation loss: 0.0734\nStored metrics: {'True_precision': 0.9679821295606851, 'False_precision': 0.1780821917808219, 'True_recall': 0.9558823529411765, 'False_recall': 0.23214285714285715, 'True_fscore': 0.9618941916389198, 'False_fscore': 0.20155038759689922, 'micro_precision': 0.9272598870056498, 'micro_recall': 0.9272598870056498, 'micro_fscore': 0.9272598870056498, 'macro_precision': 0.5730321606707535, 'macro_recall': 0.5940126050420168, 'macro_fscore': 0.5817222896179095, 'confusion_matrix': array([[  13,   43],\n       [  60, 1300]])}\nComputed metrics: {'True_precision': 0.9679821295606851, 'False_precision': 0.1780821917808219, 'True_recall': 0.9558823529411765, 'False_recall': 0.23214285714285715, 'True_fscore': 0.9618941916389198, 'False_fscore': 0.20155038759689922, 'micro_precision': 0.9272598870056498, 'micro_recall': 0.9272598870056498, 'micro_fscore': 0.9272598870056498, 'macro_precision': 0.5730321606707535, 'macro_recall': 0.5940126050420168, 'macro_fscore': 0.5817222896179095, 'confusion_matrix': array([[  13,   43],\n       [  60, 1300]])}\n\nEvaluating checkpoint: checkpoints/checkpoint_epoch_4_macroF1_0.5739_falseF1_0.1782.pt\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/118544494.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(checkpoint_path, map_location=device)\n","output_type":"stream"},{"name":"stdout","text":"Loaded checkpoint from epoch 4\nStored validation loss: 0.0746\nComputed validation loss: 0.0746\nStored metrics: {'True_precision': 0.9657184536834428, 'False_precision': 0.2, 'True_recall': 0.9735294117647059, 'False_recall': 0.16071428571428573, 'True_fscore': 0.9696082021237642, 'False_fscore': 0.1782178217821782, 'micro_precision': 0.9413841807909604, 'micro_recall': 0.9413841807909604, 'micro_fscore': 0.9413841807909604, 'macro_precision': 0.5828592268417214, 'macro_recall': 0.5671218487394958, 'macro_fscore': 0.5739130119529712, 'confusion_matrix': array([[   9,   47],\n       [  36, 1324]])}\nComputed metrics: {'True_precision': 0.9657184536834428, 'False_precision': 0.2, 'True_recall': 0.9735294117647059, 'False_recall': 0.16071428571428573, 'True_fscore': 0.9696082021237642, 'False_fscore': 0.1782178217821782, 'micro_precision': 0.9413841807909604, 'micro_recall': 0.9413841807909604, 'micro_fscore': 0.9413841807909604, 'macro_precision': 0.5828592268417214, 'macro_recall': 0.5671218487394958, 'macro_fscore': 0.5739130119529712, 'confusion_matrix': array([[   9,   47],\n       [  36, 1324]])}\n\nEvaluating checkpoint: checkpoints/checkpoint_epoch_5_macroF1_0.5734_falseF1_0.1884.pt\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/118544494.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(checkpoint_path, map_location=device)\n","output_type":"stream"},{"name":"stdout","text":"Loaded checkpoint from epoch 5\nStored validation loss: 0.0723\nComputed validation loss: 0.0723\nStored metrics: {'True_precision': 0.9677661169415293, 'False_precision': 0.15853658536585366, 'True_recall': 0.9492647058823529, 'False_recall': 0.23214285714285715, 'True_fscore': 0.9584261321455085, 'False_fscore': 0.1884057971014493, 'micro_precision': 0.9209039548022598, 'micro_recall': 0.9209039548022598, 'micro_fscore': 0.9209039548022597, 'macro_precision': 0.5631513511536914, 'macro_recall': 0.590703781512605, 'macro_fscore': 0.5734159646234789, 'confusion_matrix': array([[  13,   43],\n       [  69, 1291]])}\nComputed metrics: {'True_precision': 0.9677661169415293, 'False_precision': 0.15853658536585366, 'True_recall': 0.9492647058823529, 'False_recall': 0.23214285714285715, 'True_fscore': 0.9584261321455085, 'False_fscore': 0.1884057971014493, 'micro_precision': 0.9209039548022598, 'micro_recall': 0.9209039548022598, 'micro_fscore': 0.9209039548022597, 'macro_precision': 0.5631513511536914, 'macro_recall': 0.590703781512605, 'macro_fscore': 0.5734159646234789, 'confusion_matrix': array([[  13,   43],\n       [  69, 1291]])}\n\nEvaluating checkpoint: checkpoints/checkpoint_epoch_5_macroF1_0.5739_falseF1_0.1782.pt\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/118544494.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(checkpoint_path, map_location=device)\n","output_type":"stream"},{"name":"stdout","text":"Loaded checkpoint from epoch 5\nStored validation loss: 0.0739\nComputed validation loss: 0.0739\nStored metrics: {'True_precision': 0.9657184536834428, 'False_precision': 0.2, 'True_recall': 0.9735294117647059, 'False_recall': 0.16071428571428573, 'True_fscore': 0.9696082021237642, 'False_fscore': 0.1782178217821782, 'micro_precision': 0.9413841807909604, 'micro_recall': 0.9413841807909604, 'micro_fscore': 0.9413841807909604, 'macro_precision': 0.5828592268417214, 'macro_recall': 0.5671218487394958, 'macro_fscore': 0.5739130119529712, 'confusion_matrix': array([[   9,   47],\n       [  36, 1324]])}\nComputed metrics: {'True_precision': 0.9657184536834428, 'False_precision': 0.2, 'True_recall': 0.9735294117647059, 'False_recall': 0.16071428571428573, 'True_fscore': 0.9696082021237642, 'False_fscore': 0.1782178217821782, 'micro_precision': 0.9413841807909604, 'micro_recall': 0.9413841807909604, 'micro_fscore': 0.9413841807909604, 'macro_precision': 0.5828592268417214, 'macro_recall': 0.5671218487394958, 'macro_fscore': 0.5739130119529712, 'confusion_matrix': array([[   9,   47],\n       [  36, 1324]])}\n\nEvaluating checkpoint: checkpoints/checkpoint_epoch_5_macroF1_0.5558_falseF1_0.1527.pt\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/118544494.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(checkpoint_path, map_location=device)\n","output_type":"stream"},{"name":"stdout","text":"Loaded checkpoint from epoch 5\nStored validation loss: 0.0756\nComputed validation loss: 0.0756\nStored metrics: {'True_precision': 0.9656972408650261, 'False_precision': 0.13333333333333333, 'True_recall': 0.9522058823529411, 'False_recall': 0.17857142857142858, 'True_fscore': 0.9589041095890409, 'False_fscore': 0.15267175572519082, 'micro_precision': 0.9216101694915254, 'micro_recall': 0.9216101694915254, 'micro_fscore': 0.9216101694915254, 'macro_precision': 0.5495152870991797, 'macro_recall': 0.5653886554621849, 'macro_fscore': 0.5557879326571159, 'confusion_matrix': array([[  10,   46],\n       [  65, 1295]])}\nComputed metrics: {'True_precision': 0.9656972408650261, 'False_precision': 0.13333333333333333, 'True_recall': 0.9522058823529411, 'False_recall': 0.17857142857142858, 'True_fscore': 0.9589041095890409, 'False_fscore': 0.15267175572519082, 'micro_precision': 0.9216101694915254, 'micro_recall': 0.9216101694915254, 'micro_fscore': 0.9216101694915254, 'macro_precision': 0.5495152870991797, 'macro_recall': 0.5653886554621849, 'macro_fscore': 0.5557879326571159, 'confusion_matrix': array([[  10,   46],\n       [  65, 1295]])}\n\nEvaluating checkpoint: checkpoints/checkpoint_epoch_13_macroF1_0.5564_falseF1_0.1657.pt\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/118544494.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(checkpoint_path, map_location=device)\n","output_type":"stream"},{"name":"stdout","text":"Loaded checkpoint from epoch 13\nStored validation loss: 0.0739\nComputed validation loss: 0.0739\nStored metrics: {'True_precision': 0.967766692248657, 'False_precision': 0.12389380530973451, 'True_recall': 0.9272058823529412, 'False_recall': 0.25, 'True_fscore': 0.9470521967705595, 'False_fscore': 0.16568047337278108, 'micro_precision': 0.9004237288135594, 'micro_recall': 0.9004237288135594, 'micro_fscore': 0.9004237288135594, 'macro_precision': 0.5458302487791957, 'macro_recall': 0.5886029411764706, 'macro_fscore': 0.5563663350716703, 'confusion_matrix': array([[  14,   42],\n       [  99, 1261]])}\nComputed metrics: {'True_precision': 0.967766692248657, 'False_precision': 0.12389380530973451, 'True_recall': 0.9272058823529412, 'False_recall': 0.25, 'True_fscore': 0.9470521967705595, 'False_fscore': 0.16568047337278108, 'micro_precision': 0.9004237288135594, 'micro_recall': 0.9004237288135594, 'micro_fscore': 0.9004237288135594, 'macro_precision': 0.5458302487791957, 'macro_recall': 0.5886029411764706, 'macro_fscore': 0.5563663350716703, 'confusion_matrix': array([[  14,   42],\n       [  99, 1261]])}\n\nEvaluating checkpoint: checkpoints/checkpoint_epoch_4_macroF1_0.5558_falseF1_0.1527.pt\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/118544494.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(checkpoint_path, map_location=device)\n","output_type":"stream"},{"name":"stdout","text":"Loaded checkpoint from epoch 4\nStored validation loss: 0.0761\nComputed validation loss: 0.0761\nStored metrics: {'True_precision': 0.9656972408650261, 'False_precision': 0.13333333333333333, 'True_recall': 0.9522058823529411, 'False_recall': 0.17857142857142858, 'True_fscore': 0.9589041095890409, 'False_fscore': 0.15267175572519082, 'micro_precision': 0.9216101694915254, 'micro_recall': 0.9216101694915254, 'micro_fscore': 0.9216101694915254, 'macro_precision': 0.5495152870991797, 'macro_recall': 0.5653886554621849, 'macro_fscore': 0.5557879326571159, 'confusion_matrix': array([[  10,   46],\n       [  65, 1295]])}\nComputed metrics: {'True_precision': 0.9656972408650261, 'False_precision': 0.13333333333333333, 'True_recall': 0.9522058823529411, 'False_recall': 0.17857142857142858, 'True_fscore': 0.9589041095890409, 'False_fscore': 0.15267175572519082, 'micro_precision': 0.9216101694915254, 'micro_recall': 0.9216101694915254, 'micro_fscore': 0.9216101694915254, 'macro_precision': 0.5495152870991797, 'macro_recall': 0.5653886554621849, 'macro_fscore': 0.5557879326571159, 'confusion_matrix': array([[  10,   46],\n       [  65, 1295]])}\n\nEvaluating checkpoint: checkpoints/checkpoint_epoch_2.pt\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/118544494.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(checkpoint_path, map_location=device)\n","output_type":"stream"},{"name":"stdout","text":"Loaded checkpoint from epoch 2\nStored validation loss: 0.0999\nComputed validation loss: 0.0759\nStored metrics: {'True_precision': 0.9605654761904762, 'False_precision': 0.041666666666666664, 'True_recall': 0.9492647058823529, 'False_recall': 0.05357142857142857, 'True_fscore': 0.9548816568047337, 'False_fscore': 0.046875, 'micro_precision': 0.9138418079096046, 'micro_recall': 0.9138418079096046, 'micro_fscore': 0.9138418079096046, 'macro_precision': 0.5011160714285714, 'macro_recall': 0.5014180672268908, 'macro_fscore': 0.5008783284023668, 'confusion_matrix': array([[   3,   53],\n       [  69, 1291]])}\nComputed metrics: {'True_precision': 0.9617604617604618, 'False_precision': 0.1, 'True_recall': 0.9801470588235294, 'False_recall': 0.05357142857142857, 'True_fscore': 0.9708667152221414, 'False_fscore': 0.06976744186046512, 'micro_precision': 0.943502824858757, 'micro_recall': 0.943502824858757, 'micro_fscore': 0.943502824858757, 'macro_precision': 0.530880230880231, 'macro_recall': 0.5168592436974789, 'macro_fscore': 0.5203170785413033, 'confusion_matrix': array([[   3,   53],\n       [  27, 1333]])}\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/118544494.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcheckpoint_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheckpoint_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nEvaluating checkpoint: {checkpoint_file}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_31/118544494.py\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, checkpoint_path, data, batch_size)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'confusion_matrix'\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Confusion matrix is a numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metrics'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Mismatch in {key}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metrics'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Confusion matrix mismatch\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: Mismatch in True_precision"],"ename":"AssertionError","evalue":"Mismatch in True_precision","output_type":"error"}],"execution_count":59},{"cell_type":"code","source":"\n\n# File paths\ntrain_file = \"/kaggle/input/dataset-deception/train.jsonl\"\nval_file = \"/kaggle/input/dataset-deception/validation.jsonl\"\ntest_file = \"/kaggle/input/dataset-deception/test.jsonl\"\ncheckpoint_dir = 'checkpoints'\n\n# Preprocess train data first to get maps and stats\nuse_ling_features = True\ntrain_data, country_map, season_map, year_map, ling_stats = preprocess_data(train_file, use_ling_features=use_ling_features)\n\n# Preprocess val and test with train's maps and stats\nval_data, _, _, _, _ = preprocess_data(val_file, country_map, season_map, year_map, use_ling_features=use_ling_features, ling_stats=ling_stats)\ntest_data, _, _, _, _ = preprocess_data(test_file, country_map, season_map, year_map, use_ling_features=use_ling_features, ling_stats=ling_stats)\n\n# Initialize model parameters\nnum_countries = len(country_map)\nnum_seasons = len(season_map)\nnum_years = len(year_map)\n\n# Load the best checkpoint\ncheckpoint_path = os.path.join(checkpoint_dir, 'best_checkpoint.pt')\nif not os.path.exists(checkpoint_path):\n    # If no best checkpoint, find the one with highest macro F1\n    checkpoint_files = [f for f in os.listdir(checkpoint_dir) if f.endswith('.pt')]\n    if not checkpoint_files:\n        raise FileNotFoundError(f\"No checkpoint files found in {checkpoint_dir}\")\n    \n    # Extract metrics from checkpoint names (assuming they follow the naming convention)\n    best_macro_f1 = 0\n    best_checkpoint = None\n    for cf in checkpoint_files:\n        match = re.search(r'macroF1_([0-9\\.]+)', cf)\n        if match:\n            macro_f1 = float(match.group(1))\n            if macro_f1 > best_macro_f1:\n                best_macro_f1 = macro_f1\n                best_checkpoint = cf\n    \n    if best_checkpoint:\n        checkpoint_path = os.path.join(checkpoint_dir, best_checkpoint)\n        logger.info(f\"Using checkpoint with highest macro F1: {best_checkpoint}\")\n    else:\n        # Just use the first checkpoint if naming convention doesn't match\n        checkpoint_path = os.path.join(checkpoint_dir, checkpoint_files[0])\n        logger.info(f\"Using first available checkpoint: {checkpoint_files[0]}\")\n\nlogger.info(f\"Loading checkpoint from {checkpoint_path}\")\ncheckpoint = torch.load(checkpoint_path, map_location=device)\n\n# Initialize the model with the same parameters\nmodel = EnhancedDeceptionDetector(\n    num_countries=num_countries, num_seasons=num_seasons, num_years=num_years,\n    sentence_emb_dim=384, ling_feature_dim=6 if use_ling_features else 0,\n    country_emb_dim=16, season_emb_dim=8, year_emb_dim=8, hidden_dim=64, dropout=0.4\n).to(device)\n\n# Load model weights\nmodel.load_state_dict(checkpoint['model_state_dict'])\nmodel.eval()\n\n# Define evaluation function\ndef evaluate_checkpoint(model, data, batch_size=8):\n    total_loss = 0\n    all_preds, all_labels = [], []\n    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([checkpoint.get('pos_weight', 1.0)], device=device), reduction='none')\n    \n    with torch.no_grad():\n        for i in range(0, len(data), batch_size):\n            batch = data[i:i+batch_size]\n            messages = [c['messages'] for c in batch]\n            ling_features = [c['ling_features'] for c in batch]\n            senders = torch.nn.utils.rnn.pad_sequence([c['speakers'] for c in batch], batch_first=True, padding_value=model.country_embedding.padding_idx).to(device)\n            receivers = torch.nn.utils.rnn.pad_sequence([c['receivers'] for c in batch], batch_first=True, padding_value=model.country_embedding.padding_idx).to(device)\n            seasons = torch.nn.utils.rnn.pad_sequence([c['seasons'] for c in batch], batch_first=True, padding_value=model.season_embedding.padding_idx).to(device)\n            years = torch.nn.utils.rnn.pad_sequence([c['years'] for c in batch], batch_first=True, padding_value=model.year_embedding.padding_idx).to(device)\n            game_scores = torch.nn.utils.rnn.pad_sequence([c['game_scores'] for c in batch], batch_first=True, padding_value=0).to(device)\n            game_score_deltas = torch.nn.utils.rnn.pad_sequence([c['game_score_deltas'] for c in batch], batch_first=True, padding_value=0).to(device)\n            sender_labels = torch.nn.utils.rnn.pad_sequence([c['sender_labels'] for c in batch], batch_first=True, padding_value=-1).to(device)\n            lengths = [len(c['messages']) for c in batch]\n\n            final_pred = model(messages, ling_features, senders, receivers, seasons, years,\n                              game_scores, game_score_deltas, lengths)\n            \n            loss = criterion(final_pred.squeeze(-1), sender_labels)\n            mask = (sender_labels != -1)\n            loss = (loss * mask).sum() / (mask.sum() + 1e-8)\n            total_loss += loss.item()\n\n            all_preds.append(final_pred.squeeze(-1)[mask])\n            all_labels.append(sender_labels[mask])\n\n    avg_loss = total_loss / (len(data) / batch_size)\n    all_preds = torch.cat(all_preds)\n    all_labels = torch.cat(all_labels)\n    metrics = compute_metrics(all_preds, all_labels)\n    return avg_loss, metrics\n\n# Evaluate on all datasets\nlogger.info(\"Evaluating model on training data...\")\ntrain_loss, train_metrics = evaluate_checkpoint(model, train_data)\n\nlogger.info(\"Evaluating model on validation data...\")\nval_loss, val_metrics = evaluate_checkpoint(model, val_data)\n\nlogger.info(\"Evaluating model on test data...\")\ntest_loss, test_metrics = evaluate_checkpoint(model, test_data)\n\n# Prepare results dictionary similar to training output\nresults = {\n    'test_metrics': test_metrics,\n    'training_loss': train_loss,\n    'validation_loss': val_loss,\n    'test_loss': test_loss,\n    'best_validation_loss': checkpoint.get('val_loss', val_loss),\n    'best_validation_metrics': checkpoint.get('metrics', val_metrics)\n}\n\n# Print checkpoint info\nprint(f\"\\n📋 Checkpoint Information\")\nprint(f\"Checkpoint file: {os.path.basename(checkpoint_path)}\")\nif 'epoch' in checkpoint:\n    print(f\"Epoch: {checkpoint['epoch']}\")\n\n# Print results\nprint(\"\\n=== Per-Class Metrics (for 'True' and 'False' classes) ===\")\nprint(\"Precision\")\nprint(f\"True_precision: {results['test_metrics']['True_precision']:.4f}\")\nprint(f\"False_precision: {results['test_metrics']['False_precision']:.4f}\")\nprint(\"Recall\")\nprint(f\"True_recall: {results['test_metrics']['True_recall']:.4f}\")\nprint(f\"False_recall: {results['test_metrics']['False_recall']:.4f}\")\nprint(\"F1-Score\")\nprint(f\"True_fscore: {results['test_metrics']['True_fscore']:.4f}\")\nprint(f\"False_fscore: {results['test_metrics']['False_fscore']:.4f}\")\n\nprint(\"\\n📊 Micro-Averaged Metrics\")\nprint(f\"micro_precision: {results['test_metrics']['micro_precision']:.4f}\")\nprint(f\"micro_recall: {results['test_metrics']['micro_recall']:.4f}\")\nprint(f\"micro_fscore: {results['test_metrics']['micro_fscore']:.4f}\")\n\nprint(\"\\n📈 Macro-Averaged Metrics\")\nprint(f\"macro_precision: {results['test_metrics']['macro_precision']:.4f}\")\nprint(f\"macro_recall: {results['test_metrics']['macro_recall']:.4f}\")\nprint(f\"macro_fscore: {results['test_metrics']['macro_fscore']:.4f}\")\n\nprint(\"\\n🧠 Loss\")\nprint(f\"training_loss: {results['training_loss']:.4f}\")\nprint(f\"validation_loss: {results['validation_loss']:.4f}\")\nif 'val_loss' in checkpoint:\n    print(f\"best_validation_loss: {results['best_validation_loss']:.4f}\")\nprint(f\"test_loss: {results['test_loss']:.4f}\")\n\n# Print saved validation metrics if available\nif 'metrics' in checkpoint:\n    print(\"\\n🧪 Best Validation Metrics (from checkpoint)\")\n    for metric in ['True_precision', 'False_precision', 'True_recall', 'False_recall', \n                  'True_fscore', 'False_fscore', 'micro_precision', 'micro_recall', \n                  'micro_fscore', 'macro_precision', 'macro_recall', 'macro_fscore']:\n        if metric in checkpoint['metrics']:\n            print(f\"best_validation_{metric}: {checkpoint['metrics'][metric]:.4f}\")\n\nprint(\"\\n🔍 Test Confusion Matrix\")\nprint(results['test_metrics']['confusion_matrix'])\n\n# Evaluate all checkpoints if there are multiple\ncheckpoint_files = [f for f in os.listdir(checkpoint_dir) if f.endswith('.pt') and f != 'best_checkpoint.pt']\nif len(checkpoint_files) > 1:\n    print(\"\\n📊 Comparing All Checkpoints (Test Macro F1)\")\n    checkpoint_results = []\n    \n    for cf in checkpoint_files:\n        cp_path = os.path.join(checkpoint_dir, cf)\n        cp = torch.load(cp_path, map_location=device)\n        model.load_state_dict(cp['model_state_dict'])\n        model.eval()\n        \n        _, cp_test_metrics = evaluate_checkpoint(model, test_data)\n        checkpoint_results.append({\n            'name': cf,\n            'macro_f1': cp_test_metrics['macro_fscore'],\n            'false_f1': cp_test_metrics['False_fscore']\n        })\n    \n    # Sort by macro F1 score\n    checkpoint_results.sort(key=lambda x: x['macro_f1'], reverse=True)\n    for idx, res in enumerate(checkpoint_results):\n        print(f\"{idx+1}. {res['name']}: Macro F1 = {res['macro_f1']:.4f}, False F1 = {res['false_f1']:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T09:29:10.154109Z","iopub.execute_input":"2025-04-15T09:29:10.154742Z","iopub.status.idle":"2025-04-15T09:29:12.738914Z","shell.execute_reply.started":"2025-04-15T09:29:10.154720Z","shell.execute_reply":"2025-04-15T09:29:12.737930Z"}},"outputs":[{"name":"stderr","text":"Processing conversations:   1%|          | 2/189 [00:02<03:50,  1.23s/it]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/1168830512.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Preprocess train data first to get maps and stats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0muse_ling_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcountry_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseason_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mling_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_ling_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_ling_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Preprocess val and test with train's maps and stats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/2586692069.py\u001b[0m in \u001b[0;36mpreprocess_data\u001b[0;34m(data_file, country_map, season_map, year_map, use_ling_features, ling_stats)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0mling_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m                 \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_punct\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0mword_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1047\u001b[0m                 \u001b[0merror_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_error_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m                 \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m                 \u001b[0;31m# This typically happens if a component is not initialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/spacy/pipeline/attributeruler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0merror_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_error_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_annotations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/spacy/pipeline/attributeruler.py\u001b[0m in \u001b[0;36mmatch\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_spans\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;31m# Sort by the attribute ID, so that later rules have precedence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         matches = [\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":53},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}